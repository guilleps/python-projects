{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rM5z9ZAj1h-"
      },
      "source": [
        "Objetivo: Realizar todos los pasos dentro del proceso de preprocesamiento de datos sobre el conjunto de datos de Hotel Booking. El conjunto de datos contiene informaciÃ³n sobre reservas de hotel realizadas en dos hoteles, uno en ciudad y otro un resort.\n",
        "Cada fila consiste en una reserva del hotel.\n",
        "Incluye informaciÃ³n sobre cuando fue realizada.\n",
        "La duraciÃ³n de la estadÃ­a.\n",
        "El nÃºmero de adultos, niÃ±os y bebÃ©s entre otras cosas.\n",
        "Este conjunto de datos es ideal para practicar el anÃ¡lisis exploratorio de los datos y los conceptos de limpieza y calidad de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jjyzpdKkF46"
      },
      "source": [
        "**Paso 1. Importamos las librerÃ­as:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aqJ1bX7jowa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "import plotly.express as px\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42-gI0QYmEyM"
      },
      "source": [
        "**Paso 2. Cargamos los datos:**\n",
        "El conjunto de datos se encuentran en formato CSV (valores separados por comas).\n",
        "Existen diferentes formas de cargar el conjunto de datos, se puede cargar desde una direcciÃ³n URL o desde nuestro google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeZwsPawmFLJ"
      },
      "outputs": [],
      "source": [
        "#drive.mount('/content/drive')\n",
        "#csv_path = \"/content/drive/MyDrive/hotel_bookings.csv\"\n",
        "#df = pd.read_csv(csv_path)\n",
        "df = pd.read_csv('hotel_bookings.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvT0oyRpoNj7"
      },
      "source": [
        "**Paso 3. Conociendo los datos:**\n",
        "Para comenzar a conocer los datos podemos utilizar dos mÃ©todos que nos ayudaran a obtener un vistazo rÃ¡pido del conjunto de datos, se utilizan los comandos:\n",
        "\n",
        "dataframe.shape indica el nÃºmero de filas y columnas.\n",
        "dataframe.info indica el nÃºmero de filas, columnas y el nombre de las columnas, cuenta el nÃºmero de nulos y muestra de tipo de dato de cada columna y su cantidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRh8ZhINoOgB"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PrC1d_4orRP"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKqglxjBo4Pv"
      },
      "source": [
        "**Paso 4. Identificar los tipos de datos:**\n",
        "Exploramos los tipos de datos de cada columna. AsÃ­ mismo, identificaremos si hay alguna columna que segÃºn su significado no coincida con su tipo de dato:\n",
        "\n",
        "La funciÃ³n dtypes genera una tabla con el tipo de dato de cada columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vMmx5A8o7LP"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spB_KoASpoKM"
      },
      "source": [
        "Observamos que si hay columnas que segÃºn su significado no coincide con su tipo de dato, como por ejemplo, la columna children, presenta como tipo de dato float, sin embargo, deberÃ­a de ser int. De igual manera con la columna, reservation_status_date, deberÃ­a de ser datetime64\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6NxYScdpwys"
      },
      "source": [
        "**Paso 5. Identificar datos faltantes:**\n",
        "Para identificar los datos faltantes en el conjunto de datos se puede utilizar la funciÃ³n isnull y sumar los valores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LTL1xNOpo5d"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS-eOwRMp8QA"
      },
      "source": [
        "Observamos que la columna company presenta mÃ¡s del 50% de datos faltantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtHKggGZqDAr"
      },
      "source": [
        "**Paso 6. Identificar datos atÃ­picos:**\n",
        "Para identificar datos atÃ­picos se pueden utilizar distintos mÃ©todos, Utilicemos un grÃ¡fico de box plot para graficar una de las variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AauFshuUp9CS"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "sns.boxplot(y=df[\"stays_in_weekend_nights\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3Ed_e-lqfWa"
      },
      "source": [
        "Observamos que la mayorÃ­a de huespedes se quedan hasta cinco noches de fin de semana.\n",
        "âž¡ï¸ TambiÃ©n se pueden analizar los datos utilizando alguna variable categÃ³rica, por ejemplo, las reservas canceladas o no canceladas y vincularlo a una variable numÃ©rica como las noches de fin de semana:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su201xXIqf6p"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8,9))\n",
        "sns.boxplot(x=\"is_canceled\", y=\"stays_in_weekend_nights\", data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atV9APj1rZSH"
      },
      "source": [
        "**Paso 7. Calcular las estadÃ­sticas:**\n",
        "dataframe.describe para visualizar las estadÃ­sticas del conjunto de datos. Por defecto, la funciÃ³n describe trabaja con columnas numÃ©ricas y no con columnas de tipo object, mostrando los siguientes datos:\n",
        "\n",
        "El nÃºmero de elementos de la variable\n",
        "La media\n",
        "La desviaciÃ³n estÃ¡ndar (std)\n",
        "El valor mÃ­nimo\n",
        "Los cuartiles\n",
        "El valor mÃ¡ximo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_0eeX_krbOu"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1y6fgMIrljl"
      },
      "source": [
        "âž¡ï¸ Ahora visualizamos a las variables categÃ³ricas: agregÃ¡ndole include=['object'] podremos observar solo las columnas que son categÃ³ricas (de tipo object):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWpZ71gSrq-U"
      },
      "outputs": [],
      "source": [
        "df.describe(include=['object'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWG0_ADIr4ND"
      },
      "source": [
        "unique: para saber cuantos valores son Ãºnicos, como podemos ver en la columna hotel hay 2 valores diferentes.\n",
        "top: para ver el valor que mÃ¡s se repite, el cual es City Hotel.\n",
        "freq: la frecuencia en que se repide el valor City Hotel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceALLIebsLAC"
      },
      "source": [
        "**Paso 8. AnÃ¡lisis de tendencia central, posiciÃ³n y dispersiÃ³n:** ðŸŽ¯\n",
        "El anÃ¡lisis de la tendencia central, la simetrÃ­a y la dispersiÃ³n de los datos es importante para entender cÃ³mo se comporta cada variable:\n",
        "\n",
        "âž¡ï¸ lead_time: nÃºmero de dÃ­as entre hecha la reserva y el dÃ­a de llegada al hotel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKuPxaK9sSLa"
      },
      "outputs": [],
      "source": [
        "df['lead_time'].hist(figsize = (6,6))\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJVi-3QxsnYS"
      },
      "source": [
        "Este grÃ¡fico muestra un sesgo positivo hacia la derecha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3JSPd1Vsr4o"
      },
      "outputs": [],
      "source": [
        "mean = df['lead_time'].mean()\n",
        "median = df['lead_time'].median()\n",
        "mode = df['lead_time'].mode()\n",
        "skew = df['lead_time'].skew()\n",
        "kurt = df['lead_time'].kurt()\n",
        "\n",
        "print(\"La media es:\", mean)\n",
        "print(\"La mediana es:\", median)\n",
        "print(\"La moda es:\", mode)\n",
        "print(\"El sesgo es:\", skew)\n",
        "print(\"La kurtosis es:\", kurt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InBQ47myszwI"
      },
      "source": [
        "âž¡ï¸ arrival_date_week_number: nÃºmero de la semana del aÃ±o en que llega el huesped al hotel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV3CGVd2s55G"
      },
      "outputs": [],
      "source": [
        "df['arrival_date_week_number'].hist(figsize = (6,6))\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7MDUSy9tIkQ"
      },
      "outputs": [],
      "source": [
        "mean = df['arrival_date_week_number'].mean()\n",
        "median = df['arrival_date_week_number'].median()\n",
        "mode = df['arrival_date_week_number'].mode()\n",
        "skew = df['arrival_date_week_number'].skew()\n",
        "kurt = df['arrival_date_week_number'].kurt()\n",
        "\n",
        "print(\"La media es:\", mean)\n",
        "print(\"La mediana es:\", median)\n",
        "print(\"La moda es:\", mode)\n",
        "print(\"El sesgo es:\", skew)\n",
        "print(\"La kurtosis es:\", kurt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF_islZJszsw"
      },
      "source": [
        "**Paso 9. Contando datos duplicados:**\n",
        "Para ver los datos duplicados del conjunto de datos llamamos al mÃ©todo duplicated() en el DataFrame. Si luego llamamos al mÃ©todo SUM, obtendremos el total de duplicados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLDAI0mXtS5d"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_CSb2G6tXeN"
      },
      "source": [
        "Observamos que existen 31994 filas con los mismos datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmtojmWqtbTV"
      },
      "source": [
        "**Paso 10. ExploraciÃ³n y visualizaciÃ³n de los datos:**\n",
        "Utilizando tecnicas de visualizaciÃ³n se puede comenzar a comprender el contexto alrededor de los datos, se van a realizar diferentes preguntas capaces de brindar informaciÃ³n interesante.\n",
        "\n",
        "Estas preguntas nos ayudan a encontrar anÃ¡lisis significativos sin siquiera aplicar alguna tÃ©cnica de analÃ­tica.\n",
        "Se comprende mejor el mundo de las reservas de hoteles, asÃ­ como las necesidades que les pueden surgir a las empresas y que se tratan de solucionar con herramientas analÃ­ticas.\n",
        "Empezaremos a analizar las variables numÃ©ricas y luego las categÃ³ricas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftLuwreEtnl8"
      },
      "source": [
        "**10.1. AnÃ¡lisis de variables numÃ©ricas:**\n",
        "Explorando las variables numÃ©ricas observamos su distribuciÃ³n. Se puede utilizar el diagrama de hist para visualizar todos los histogramas de las variables numÃ©ricas dentro del dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m78RlGSthIU"
      },
      "outputs": [],
      "source": [
        "df.hist(figsize=(20,15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lb0KX-gtylj"
      },
      "source": [
        "âž¡ï¸ TambiÃ©n se puede analizar cada variable de manera independiente. En este grÃ¡fico se muestra el histograma de la variable arrival_Date_week_number que muestra las diferentes semanas del aÃ±o 1-52, donde los clientes reservan o se hospedan en los hoteles:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqcbPC52t_sC"
      },
      "outputs": [],
      "source": [
        "df['arrival_date_week_number'].hist(figsize = (6,6))\n",
        "plt.xlabel('arrival_date_week_number')\n",
        "plt.ylabel('Cantidad')\n",
        "plt.title('Histograma arrival_date_week_number', fontweight = \"bold\")\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrGbCzjquFLK"
      },
      "source": [
        "âž¡ï¸ En este histograma se aprecia la distribuciÃ³n de la variable adr (tarifa diaria promedio):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vhm5XuHuJDR"
      },
      "outputs": [],
      "source": [
        "df['adr'].hist(figsize = (6,6))\n",
        "plt.xlabel('Average Daily Rate')\n",
        "plt.ylabel('Cantidad')\n",
        "plt.title('Histograma adr', fontweight = \"bold\")\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlhPZb22uSKK"
      },
      "source": [
        "âž¡ï¸ Para visualizar la relaciÃ³n entre dos variables numÃ©ricas se utiliza un grÃ¡fico de lÃ­neas. Este combina las variables de mes de llegada arrival_date_month y tarifa promedio adr. Como tenemos variables que representan tiempo (aÃ±os, meses, semanas, fecha) se puede realizar un anÃ¡lisis en el tiempo para ver su comportamiento. La temporada alta es junio, julio, agosto y la temporada baja es noviembre, diciembre y enero:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV4SrgwUuXMq"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(7,4), dpi=100)\n",
        "plt.xticks(rotation = 45, fontsize=10)\n",
        "sns.lineplot(data=df, x = 'arrival_date_month', y = 'adr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wVwJKBPuhLw"
      },
      "source": [
        "âž¡ï¸ Ahora hacemos lo mismo, pero con el nÃºmero de semana del aÃ±o arrival_date_week_number:\n",
        "\n",
        "Vemos que el grÃ¡fico coincide, ya que el nÃºmero de semana coincide con el mes del aÃ±o."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPFgXUsduitE"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(7,4), dpi=100)\n",
        "plt.xticks(rotation = 45, fontsize=10)\n",
        "sns.lineplot(data=df, x = 'arrival_date_week_number', y = 'adr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmOYfXqnuo-p"
      },
      "source": [
        "**10.2. AnÃ¡lisis de variables categÃ³ricas:**\n",
        "Para analizar las variables categÃ³ricas, seleccionamos primero el subconjunto del dataframe y visualizamos los valores de cada categorÃ­a. Identificamos algÃºn valor que no corresponda con el negocio.\n",
        "\n",
        "Seleccionar las variables categÃ³ricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t26ca1iuvNA"
      },
      "outputs": [],
      "source": [
        "df_cat = df.select_dtypes(include=['object'])\n",
        "df_cat.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8niDKk5u0-n"
      },
      "source": [
        "La columna reservation_status_date se muestra como tipo de dato categÃ³rico, sin embargo, deberÃ­a de ser datetime64 mÃ¡s adelante se harÃ¡ el cambio.\n",
        "âž¡ï¸ Visualizar los valores de cada una de las variables:\n",
        "\n",
        "Esto nos ayuda a identificar valores que no coinciden con el dominio del negocio, de ser asÃ­, lo eliminarÃ­amos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v-D7GiHu6hZ"
      },
      "outputs": [],
      "source": [
        "for col in df_cat.columns:\n",
        "  print(f\"{col}: \\n{df_cat[col].unique()}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc_G5Wq8vM7O"
      },
      "source": [
        "âž¡ï¸ Ahora, utilizando grÃ¡ficos se observa la proporciÃ³n entre las distintas categorÃ­as.\n",
        "\n",
        "GrÃ¡fico que muestra a la variable si la reserva fue cancelada o no:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dluiBG-vOMt"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df, x = 'is_canceled')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvJ7CHLBvdYm"
      },
      "source": [
        "âž¡ï¸ InclinaciÃ³n de los clientes por los distintos tipos de habitaciÃ³n:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uH-gOqMjvevW"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df, x = 'reserved_room_type')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlYbXA8WvmB8"
      },
      "source": [
        "Observamos que el tipo de habitaciÃ³n A es la que mÃ¡s se ha reservado.\n",
        "âž¡ï¸ Por dÃ³nde se realizaron las reservas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnCeqZmdvm_U"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df, x= 'market_segment')\n",
        "plt.xticks(rotation=45, fontsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywCaYzVkv11j"
      },
      "source": [
        "Observamos que la mayorÃ­a de reservas se hicieron por Online TA.\n",
        "âž¡ï¸ AnÃ¡lisis de las reservas que no fueron canceladas, segÃºn el segmento del mercado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlSi5MAaxBpX"
      },
      "outputs": [],
      "source": [
        "#Separamos los grupos por tipo de hotel y solo con reservas no canceladas:\n",
        "rh = pd.DataFrame(df.loc[(df['hotel'] == 'Resort Hotel') & (df['is_canceled'] == 0)])\n",
        "ch = pd.DataFrame(df.loc[(df['hotel'] == 'City Hotel') & (df['is_canceled'] == 0)])\n",
        "\n",
        "#Ajustamos tamaÃ±o de la figura:\n",
        "fig = plt.figure(figsize = (16, 9))\n",
        "\n",
        "#Pie de Resort Hotel:\n",
        "ax = fig.add_subplot(121)\n",
        "rh_segment_pie = pd.DataFrame(rh['market_segment'].value_counts())\n",
        "ax.set_title('The Market segment of Resort Hotel', fontsize = 14)\n",
        "# rh_segment_pie['market_segment'] does not exist, it is actually in the index\n",
        "# Use rh_segment_pie['count'] instead to access the values for the pie chart\n",
        "# and rh_segment_pie.index to access the labels\n",
        "ax.pie(x = rh_segment_pie['count'], labels = rh_segment_pie.index, autopct = '%.3f%%')\n",
        "\n",
        "#Pie de City Hotel:\n",
        "ax = fig.add_subplot(122)\n",
        "ch_segment_pie = pd.DataFrame(ch['market_segment'].value_counts())\n",
        "ax.set_title('The Market segment of City Hotel', fontsize = 14)\n",
        "# Similarly, use ch_segment_pie['count'] for the values and ch_segment_pie.index for the labels\n",
        "ax.pie(x = ch_segment_pie['count'], labels = ch_segment_pie.index, autopct = '%.3f%%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsqXd0-CxXmo"
      },
      "source": [
        "**Paso 11. Combinando variables:**\n",
        "DespuÃ©s de analizar las variables de manera individual para comprender su comportamiento, se pueden encontrar relaciones interesantes entres dos, tres o cuatro variables. A continuaciÃ³n se responden algunas preguntas interesantes:\n",
        "\n",
        "âž¡ï¸ Â¿QuÃ© tipo de hotel tiene el mayor nÃºmero de cancelaciones?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kewdVBCvxb44"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df, x = 'hotel', hue='is_canceled')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TudQbIZUxjn4"
      },
      "source": [
        "âž¡ï¸ Â¿CuÃ¡les son los paises mÃ¡s visitados?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Upur-aIBxnUA"
      },
      "outputs": [],
      "source": [
        "paises_mas_visitas = df[df['is_canceled'] == 0]['country'].value_counts().reset_index()\n",
        "paises_mas_visitas.columns = ['country', 'No of guests']\n",
        "paises_mas_visitas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWoc6ZxExwfO"
      },
      "source": [
        "âž¡ï¸ Mapa para visualizar los paises anteriores y la cantidad de visitantes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpNUWoB5x0IG"
      },
      "outputs": [],
      "source": [
        "basemap = folium.Map()\n",
        "guests_map = px.choropleth(\n",
        "    paises_mas_visitas,\n",
        "    locations = paises_mas_visitas['country'],\n",
        "    color_continuous_scale=\"portland\",\n",
        "    color = paises_mas_visitas['No of guests'],\n",
        "    hover_name = paises_mas_visitas['country']\n",
        ")\n",
        "\n",
        "guests_map.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8acAqVt1x-xs"
      },
      "source": [
        "âž¡ï¸ Â¿CuÃ¡nto se paga por una noche de alojamiento?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDpkCSY5yDCC"
      },
      "outputs": [],
      "source": [
        "# Filtramos las reservas no canceladas\n",
        "cuanto_se_paga = df[df['is_canceled'] == 0]\n",
        "plt. figure (figsize= (12,8))\n",
        "\n",
        "sns.boxplot(x='reserved_room_type', y='adr', data=cuanto_se_paga, hue='hotel')\n",
        "plt.title('Precio por tipo de habitaciÃ³n por noche', fontsize=16)\n",
        "plt.xlabel('Tipo de HabitaciÃ³n')\n",
        "plt.ylabel('Precio en [EUR]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zIcbCi7yPTk"
      },
      "source": [
        "âž¡ï¸ Â¿Existe alguna relaciÃ³n entre el nÃºmero de dÃ­as transcurridos desde la reserva y las cancelaciones?\n",
        "\n",
        "lead_time: num dÃ­as transcurridos entre la fecha de reserva y el dia de llegada al hotel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaV_Ygx4ySgz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize= (12, 6))\n",
        "sns.barplot(x='arrival_date_year', y='lead_time', hue='is_canceled', data = df)\n",
        "plt.title ('Alo de llegada, Anticipo y Cancelaciones')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AS0N_D5yZ73"
      },
      "source": [
        "âž¡ï¸ Â¿Se distribuyen de forma homogÃ©nea las llegadas dependiendo del mes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH1nP-VVydzD"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15,6))\n",
        "sns.countplot(data = df, x = 'arrival_date_day_of_month', hue = 'hotel')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIicCa1dynRb"
      },
      "source": [
        "Se concluye que se distribuyen de forma razonablemente homogenea. El valor mÃ¡s bajo se registra los dÃ­as 31, esto se debe a que no todos los meses tienen 31 dÃ­as y por tanto el recuento de llegadas es inferior.\n",
        "âž¡ï¸ Â¿QuÃ© tipo de rÃ©gimen de pensiÃ³n eligen los huÃ©spedes?\n",
        "\n",
        "SC: No meal\n",
        "BB: Bed and Breakfast\n",
        "HB: Half board\n",
        "FB: Full board (pensiÃ³n completa)\n",
        "Undefined: No definido el rÃ©gimen de comida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7Uj34S4yoqr"
      },
      "outputs": [],
      "source": [
        "meal_labels = ['BB','B', 'SC', 'Sin definir', 'FB']\n",
        "size = df['meal'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "cmap = plt.get_cmap(\"Pastel2\")\n",
        "colors = cmap(np.arange(6)*1)\n",
        "my_circle = plt.Circle((0,0), 0.7, color = 'white')\n",
        "\n",
        "plt.pie(size, labels=meal_labels, colors=colors, wedgeprops = {'linewidth' : 3, 'edgecolor' : 'white' })\n",
        "p=plt.gcf()\n",
        "p.gca().add_artist(my_circle)\n",
        "plt.title('Tipo de rÃ©gimen', weight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrnPDl4Fy6-x"
      },
      "source": [
        "La mayorÃ­a de las reservas son con rÃ©gimen de cama de desayuno (Bed & Breakfast) y sÃ³lo una parte muy pequeÃ±a elije pensiÃ³n completa (Full Board)\n",
        "âž¡ï¸ Se puede analizar el comportamiento de un paÃ­s en especÃ­fico, utilicemos EspaÃ±a como ejemplo:\n",
        "\n",
        "Cantidad de reservas en EspaÃ±a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt9dwbe9y8hI"
      },
      "outputs": [],
      "source": [
        "reservation_date_Spain = df[df['country'] == \"ESP\"][df['is_canceled'] == 0]['arrival_date_year'].value_counts().reset_index()\n",
        "reservation_date_Spain.columns = ['AÃ±o', 'NÂ° Reservas']\n",
        "reservation_date_Spain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCBlLYT_zDZZ"
      },
      "source": [
        "Se visualizan los resultados de EspaÃ±a:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmJ9pxjozGh5"
      },
      "outputs": [],
      "source": [
        "sns.barplot(x = \"AÃ±o\", y = \"NÂ° Reservas\", data = reservation_date_Spain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wb53fyTzWog"
      },
      "source": [
        "âž¡ï¸ Ahora analizamos el comportamiento de la cantidad de reservas en PerÃº:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te3EfMwJzbSB"
      },
      "outputs": [],
      "source": [
        "reservation_date_Peru = df[df['country'] == \"PER\"][df['is_canceled'] == 0] ['arrival_date_year'].value_counts().reset_index()\n",
        "reservation_date_Peru.columns = ['AÃ±o', 'NÂ° Reservas']\n",
        "reservation_date_Peru"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsJ_sORezjpn"
      },
      "source": [
        "âž¡ï¸ Se visualizan los resultados de PerÃº:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx7LhpD9zi-u"
      },
      "outputs": [],
      "source": [
        "sns.barplot(x = \"AÃ±o\", y = \"NÂ° Reservas\", data = reservation_date_Peru)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R1NE8fHzsYf"
      },
      "source": [
        "âž¡ï¸ Â¿CuÃ¡l es el paÃ­s con mÃ¡s hoteles y de quÃ© tipo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9O4S4j3zvhu"
      },
      "outputs": [],
      "source": [
        "counts = df['country'].value_counts()\n",
        "plt.subplots(figsize = (10, 5))\n",
        "sns.countplot(x= 'country', hue='hotel', data=df[df['country'].isin(counts[counts > 2000].index)])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saPhWkthz7wl"
      },
      "outputs": [],
      "source": [
        "counts = df['country'].value_counts()\n",
        "counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv9hxJOS0DTf"
      },
      "source": [
        "âž¡ï¸ Analizamos la relaciÃ³n entre las variables â€œDeposit typeâ€ y â€œis_canceledâ€:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlXU1wAq0Eq9"
      },
      "outputs": [],
      "source": [
        "deposit_cancel_data = df.groupby(\"deposit_type\")[\"is_canceled\"].describe()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=deposit_cancel_data.index, y=deposit_cancel_data [\"mean\"] * 100)\n",
        "plt.title(\"Influencia del depÃ³sito en la cancelaciÃ³n\", fontsize=16)\n",
        "plt.xlabel(\"Tipo de depÃ³sito\", fontsize=16)\n",
        "plt.ylabel(\"Cancelaciones [%]\", fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND1HknDC0MLM"
      },
      "source": [
        "âž¡ï¸ De este anÃ¡lisis exploratorio de los datos se puede concluir lo siguiente:\n",
        "\n",
        "La indudable importancia de la variable hotel, referida al tipo de hotel que se estÃ¡ reservando, pues como hemos podido ver en varios grÃ¡ficos, la diferencia en la interpretaciÃ³n es considerable cuando hablamos de un resort frente a un hotel de ciudad.\n",
        "Por otro lado, las peculiaridades en ciertas variables como â€œlead_timeâ€, â€œBooking_changesâ€ y â€œprevious_cancellationsâ€, las cuales se considera que pueden tener un peso considerable para predecir de una manera mÃ¡s precisa futuras cancelaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTCFIHfiz2vW"
      },
      "source": [
        "**Paso 12. Limpieza de datos:**\n",
        "Resolveremos problemas de calidad\n",
        "âž¡ï¸ Resolver problema de datos faltantes, observemos quÃ© variables tienen datos faltantes y quÃ© se puede hacer en cada caso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC_J766v0QGF"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D5_bmNw0kGC"
      },
      "outputs": [],
      "source": [
        "df[[\"children\", \"country\", \"agent\", \"company\"]].describe(include=\"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USYbu9-t0ggc"
      },
      "source": [
        "âž¡ï¸ La cantidad de datos faltantes en la columna company hace que no sea Ãºtil sustituirlos o imputarlos, pues faltan muchos datos y modificarlos supondrÃ­a una grave alteraciÃ³n de los datos.\n",
        "\n",
        "âž¡ï¸ La columna agent no estÃ¡ en la misma situaciÃ³n pero no aporta gran valor pues solo es el identificador de los agentes, no el nombre en si. Por tanto se procede a eliminar esas variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kVUuiXY0veK"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['company', 'agent'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0TTmNJA013i"
      },
      "source": [
        "âž¡ï¸ Para trabajar las columnas country y children una alternativa es eliminar los registros que tienen NA:\n",
        "\n",
        "A modo de ejemplo lo eliminamos, pero lo almacenamos en otro DataFrame (df1):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9JhaHbK04BC"
      },
      "outputs": [],
      "source": [
        "df1 = df.dropna (subset=['country', 'children'], axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xFGJGwJiiyn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA8vIzF309B5"
      },
      "outputs": [],
      "source": [
        "print(df1.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cySP8Yv21HO5"
      },
      "source": [
        "âž¡ï¸ Otra alternativa es sustituir la variable con un valor.\n",
        "\n",
        "Para la columna country que es categÃ³rica serÃ­a sustituir con la Moda.\n",
        "El paÃ­s mÃ¡s comÃºn es PRT (Portugal). Por ello, sustituÃ­mos por PRT a los datos faltantes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWfy6MEz1Ijv"
      },
      "outputs": [],
      "source": [
        "df[\"country\"].replace(np.nan, \"PRT\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRjN_jeM1iQX"
      },
      "source": [
        "Para la variable children que es numÃ©rica serÃ­a necesario analizar su simetrÃ­a y luego sustituir con su media o mediana:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSAk5tiy1lve"
      },
      "outputs": [],
      "source": [
        "sns.displot(df[\"children\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch1icRwB1uHe"
      },
      "outputs": [],
      "source": [
        "mean = df['children'].mean()\n",
        "median = df['children'].median()\n",
        "mode = df['children'].mode()\n",
        "skew = df['children'].skew()\n",
        "kurt = df['children'].kurt()\n",
        "\n",
        "print(\"La media es:\", mean)\n",
        "print(\"La mediana es:\", median)\n",
        "print(\"La moda es:\", mode)\n",
        "print(\"El sesgo es:\", skew)\n",
        "print(\"La kurtosis es:\", kurt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77nKcIOX1qcO"
      },
      "source": [
        "âž¡ï¸ A los datos faltantes lo sustituÃ­mos por 0, porque su mediana es 0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA1vGRKF11Hf"
      },
      "outputs": [],
      "source": [
        "df[\"children\"].replace(np.nan, 0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdKvX6bJ2Gmk"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5NssUcB2CHN"
      },
      "source": [
        "**Paso 13. Tipos de datos:**\n",
        "La columna children tiene como tipo de dato float, pero deberÃ­a ser int, entonces procedemos a cambiarle su tipo de dato, lo mismo hacemos para la columna reservation_status_date lo cambiamos de tipo object a DateTime:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSuc9miA2O7M"
      },
      "outputs": [],
      "source": [
        "df[[\"children\"]] = df[[\"children\"]].astype(\"int\")\n",
        "df['reservation_status_date'] = pd.to_datetime(df['reservation_status_date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9DOET4a2XLD"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqYnUwer2ey0"
      },
      "source": [
        "**Paso 14. Datos inconsistentes:**\n",
        "Al analizar las caracteristicas de las reservas, en concreto en lo que se refiere a los huÃ©spedes, se puede observar que existen registros que cumplen con la condiciÃ³n de que: (data.children == 0) & (data.adults == 0) & (data.babies == 0)\n",
        "No puede haber Oâ€™s en una misma observaciÃ³n en adults, children y babies (no se puede hacer una reserva sin huÃ©spedes).\n",
        "Estos registros se deben eliminar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiM-eq3X2ge0"
      },
      "outputs": [],
      "source": [
        "filter = (df.children == 0) & (df.adults == 0) & (df.babies == 0)\n",
        "sum(filter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZurSpxOA2oGF"
      },
      "source": [
        "âž¡ï¸ Se concluye que se trata de un error, por lo que se procede a eliminarlos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz-uI8WB2sKV"
      },
      "outputs": [],
      "source": [
        "df = df[~filter]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUNQMp9S2xii"
      },
      "source": [
        "âž¡ï¸ ComprobaciÃ³n de que no hay registros que sumen cero y por tanto el nÃºmero de registros total es correcto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNOoAsvQ223y"
      },
      "outputs": [],
      "source": [
        "#Total de huÃ©spedes:\n",
        "df['Total_Guests'] = df['adults'] + df['children']\n",
        "\n",
        "#Comprobamos que efectivamente no hay ningÃºn registro que sume 0:\n",
        "filter = df.Total_Guests != 0\n",
        "df.drop(\"Total_Guests\", axis=1, inplace=True)\n",
        "sum(filter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au-kw0yv211y"
      },
      "source": [
        "df.drop(\"Total_Guests\", axis=1, inplace=True): Eliminamos la columna porque solo era para probar\n",
        "El nÃºmero de registros total son 119210, asi que es correcto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvtPNzyM3HcZ"
      },
      "source": [
        "**Paso 15. Datos atÃ­picos:**\n",
        "Se comienza con la detecciÃ³n de outliers visualizando los boxplot de las diferentes variables que conforman nuestro modelo. De su visualizaciÃ³n obtenemos un total de 8 variables que presentan cierta problemÃ¡tica: â€˜lead timeâ€™, â€˜stays in weekend nightsâ€™, â€˜stays in week nights, â€˜adultsâ€™, â€œbabiesâ€™, â€˜required car parking spacesâ€™, â€˜adr, â€˜previous cancellationsâ€™."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMuaE8Jg3CiY"
      },
      "outputs": [],
      "source": [
        "columnas = ['lead_time', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults',\n",
        "            'babies', 'required_car_parking_spaces', 'adr', 'previous_cancellations']\n",
        "n = 1\n",
        "plt.figure(figsize = (20, 15))\n",
        "\n",
        "for column in columnas:\n",
        "  plt.subplot(4, 4, n)\n",
        "  n = n + 2\n",
        "  sns.boxplot (y=df[column])\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6gorFRA3BfC"
      },
      "source": [
        "âž¡ï¸ Se procede a sustituir la mayoria de los valores atÃ­picos por otros dentro del Ãºltimo cuartil o por el valor cero dependiendo del caso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G96HY4dS3gQr"
      },
      "outputs": [],
      "source": [
        "df.loc[df.lead_time > 400, 'lead time'] = 400\n",
        "df.loc[df.stays_in_weekend_nights >= 5, 'stays_in_weekend_nights'] = 5\n",
        "df.loc[df.stays_in_week_nights > 20, 'stays_in_week_nights'] = 20\n",
        "df.loc[df.adults > 10, 'adults'] = 10\n",
        "df.loc[df.babies > 8, 'babies'] = 0\n",
        "df.loc[df.required_car_parking_spaces > 5, 'required_car_parking_spaces'] = 0\n",
        "df.loc[df.adr > 1000, 'adr'] = 1000\n",
        "df.loc[df.adr < 30, 'adr'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udplcCpn3n53"
      },
      "outputs": [],
      "source": [
        "df['adr'].plot(kind = 'hist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcXNxUVy3tU_"
      },
      "source": [
        "âž¡ï¸ Cuando se quiere analizar todas las variables para saber si hay registros atÃ­picos e inconsistentes entre ellas, se puede utilizar el algoritmo de LOF. Para el ejemplo se utiliza una selecciÃ³n de las variables numÃ©ricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQNFrHFp3uR_"
      },
      "outputs": [],
      "source": [
        "#Seleccionar columnas:\n",
        "select_df = df[['lead_time', 'arrival_date_year', 'stays_in_weekend_nights', 'adults',\n",
        "                'is_repeated_guest', 'previous_cancellations', 'required_car_parking_spaces',\n",
        "                'adr']]\n",
        "\n",
        "#Especificar el modelo que se va a utilizar:\n",
        "model = LocalOutlierFactor(n_neighbors = 30)\n",
        "\n",
        "#Ajuste al modelo:\n",
        "y_pred = model.fit_predict(select_df)\n",
        "y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUyj-9Z_38WF"
      },
      "outputs": [],
      "source": [
        "#Filtrar los indices de los outliers\n",
        "outlier_index = (y_pred == - 1) #los valores negativos son outliers\n",
        "\n",
        "#Filtrar los valores de los outliers en el dataframe\n",
        "outlier_values = select_df.iloc[outlier_index]\n",
        "outlier_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsosmlqQ4Cj-"
      },
      "source": [
        "Se obtuvieron 6397 muestras como atÃ­picos, si se aplica una tÃ©cnica basado en distancias, es importante eliminar los datos atÃ­picos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbUxoS0n4HN1"
      },
      "source": [
        "**Paso 16. Datos redundantes:**\n",
        "Para identificar los atributos redundantes se pueden utilizar la matriz de correlaciÃ³n e indentificar correlaciones entre atributos.\n",
        "La matriz de correlaciÃ³n solo se calcula sobre atributos numÃ©ricos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkV3-S4s4Slk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (24, 12))\n",
        "# Select only numeric features for correlation calculation\n",
        "numeric_df = df.select_dtypes(include=['number'])\n",
        "corr = numeric_df.corr()\n",
        "sns.heatmap(corr, annot = True, linewidths = 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oFsjTWu4hQT"
      },
      "source": [
        "**Paso 17. Datos duplicados:**\n",
        "El anÃ¡lis de datos duplicados en este conjunto es interesante.\n",
        "\n",
        "Existen muchas filas duplicadas, sin embargo en algunos casos pudieran ser coincidencias de reservas iguales, para clientes diferentes.\n",
        "En este caso es mejor indagar un poco en el negocio para saber cual es realmente la posibilidad de reservas identicas.\n",
        "En Ãºltimo recursos, si se eliminan todos los duplicados, quedarÃ­an aÃºn suficientes datos para realizar un anÃ¡lisis interesante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWxmU8uQ4ij0"
      },
      "outputs": [],
      "source": [
        "#Contando los duplicados de todo el dataframe:\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfOSpCVT4rjV"
      },
      "outputs": [],
      "source": [
        "#Permite ver las filas duplicadas de todo el dataframe\n",
        "df.loc[df.duplicated(), :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLkRNV2l45Q6"
      },
      "outputs": [],
      "source": [
        "#Si se quisiera eliminar los duplicados\n",
        "df_drop = df.drop_duplicates()\n",
        "df_drop.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr7f1LyD4n5D"
      },
      "source": [
        "**Paso 18. Transformaciones a los datos:**\n",
        "Las transformaciones que se van a aplicar a continuaciÃ³n dependen de la tÃ©cnica analitica a aplicar. No siempre es necesario aplicarlas todas. En este notebook se aplicarÃ¡n todas a manera de ejemplo.\n",
        "Es importante tener claras las necesidades de cada tÃ©cnica para aplicar lo mÃ¡s adecuado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeToeJU6GMd-"
      },
      "source": [
        "**18.1. NormalizaciÃ³n:**\n",
        "La normalizaciÃ³n o escalamiento es necesario para poner todas las variables numÃ©ricas en la misma escala.\n",
        "Las tÃ©cnicas basadas en distancias siempre necesitan normalizaciÃ³n. A continuaciÃ³n se normalizan las variales numÃ©ricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1eKQ9Me5A76"
      },
      "outputs": [],
      "source": [
        "df_normalize = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZHY4n895EVp"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "df_normalize[['lead_time', 'arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
        "              'stays_in_week_nights', 'adr']] = scaler.fit_transform(df_normalize[['lead_time',\n",
        "              'arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adr']])\n",
        "\n",
        "df_normalize[['lead_time', 'arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
        "              'stays_in_week_nights', 'adr']].tail(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw2Ec6L85JKS"
      },
      "source": [
        "**18.2. DiscretizaciÃ³n:**\n",
        "Para realizar un ejemplo de discretizaciÃ³n se utiliza la variable lead_time que significa los dÃ­as de antelaciÃ³n con la que se realiza una reserva. Primero se visualiza la distribuciÃ³n de la variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nijW-Fqv5MnR"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "sns.boxplot(y=df[\"lead_time\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOfAhObX5XJz"
      },
      "source": [
        "âž¡ï¸ A continuaciÃ³n se diseÃ±an los grupos (bins) por los cuales se desea discretizar la variable y se realiza la discretizaciÃ³n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emrIMz1G5YVK"
      },
      "outputs": [],
      "source": [
        "nivelAntelacion = ['Ninguno', '2-3Semanas', '1Mes', '2Meses', '3Meses', 'Mas3Meses']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-8zSgbX5gw3"
      },
      "outputs": [],
      "source": [
        "df['lead_time_binned'] = pd.cut(x = df['lead_time'],\n",
        "                      bins = [0, 1, 21, 30, 60, 120, 737],\n",
        "                      labels = nivelAntelacion, include_lowest = True)\n",
        "df[['lead_time', 'lead_time_binned']].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhq9ovrK5oDX"
      },
      "source": [
        "âž¡ï¸ Una vez discretizada la variable se visualizan los resultados, se puede observar que la mayor proporsiÃ³n de ejemplos permanecen en la categorias de Mas3Meses. Tambien se analiza cÃ³mo se comportan las cancelaciones con respecto a la nueva variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_Pvdr0z5pGn"
      },
      "outputs": [],
      "source": [
        "sns.catplot(x=\"lead_time_binned\", kind=\"count\", data=df, height = 6, aspect = 1.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BlY6dJY5y-f"
      },
      "outputs": [],
      "source": [
        "sns.catplot(x=\"lead_time_binned\", hue = 'is_canceled', kind=\"count\", data=df, height = 6, aspect = 1.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e-nxbkS52N_"
      },
      "source": [
        "**Paso 19. NumerizaciÃ³n:**\n",
        "El objetivo de numerizar es convertir a nÃºmero distintas variables que son categÃ³ricas, esto puede ser muy necesario para ciertas tÃ©cnicas que solo funcionan con datos numÃ©ricos. A continuaciÃ³n se muestra cÃ³mo numerizar distintas variables del conjunto de datos segÃºn su tipo y valor.\n",
        "Las siguientes variables se pueden numerizar 1 a 1, esto significa que podemos sustituir los valores por nÃºmeros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqJN8Cp-55zi"
      },
      "outputs": [],
      "source": [
        "# Numerizar 1 a 1\n",
        "df_cat['hotel'] = df_cat['hotel'].map({'Resort Hotel' : 0, 'City Hotel' : 1})\n",
        "df_cat['reserved_room_type'] = df_cat['reserved_room_type'].map({'A': 0, 'B': 1,\n",
        "                        'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'L': 8})\n",
        "df_cat.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkxnkHdK6C3f"
      },
      "source": [
        "âž¡ï¸ Observe y analice los valores de la variable meal:\n",
        "\n",
        "SC: No meal\n",
        "BB: BED AND BREAKFAST\n",
        "HB: Half board\n",
        "FB: FULL BOARD (PENSIÃ“N COMPLETA)\n",
        "Undefined: No definido el rÃ©gimen de comida\n",
        "âž¡ï¸ Si no estuviera la categorÃ­a de Undefined, se pusiera numerizar 1 a 1, pero al existir, no es posible. Se puedieran eliminar esos registros o tratarlos como datos faltantes, si son pocos.\n",
        "\n",
        "âž¡ï¸ Observe y analice la variable market_segment:\n",
        "\n",
        "Direct\n",
        "Corporate\n",
        "Online Travel Agents\n",
        "Offline Travel Agents/Tours Operators\n",
        "Complementary\n",
        "Groups\n",
        "Undefined\n",
        "Aviontion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta0I-3oY6MA_"
      },
      "source": [
        "âž¡ï¸ Â¿Pueden determinar un orden natural en los datos? No se puede. Numerizar de esta forma serÃ­a un error:\n",
        "\n",
        "cat df/market_segment] = cat_df/market segment)map(f Direct: 0, â€œCorporate: 1, Online TA: 2, Ofine TA/TO: 3, â€˜Complementary: 4, â€˜Groupsâ€™: 5, Undefined: 6, â€˜Aviationâ€™: 7))\n",
        "\n",
        "âž¡ï¸ Para las siguientes variables no se puede realizar el mismo proceso, pues son variables Nominales, no tienen un orden natural, y numerizarlas 1 a 1 serÃ­a introducir un error grave en los datos y en las salidas de cualquier algoritmo. Hay que numerizar de 1 a N, creando variable dummies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZF8vCxu6V-k"
      },
      "outputs": [],
      "source": [
        "df_cat = pd.get_dummies(df_cat, columns = [\"distribution_channel\"])\n",
        "df_cat = pd.get_dummies(df_cat, columns = [\"customer_type\"])\n",
        "df_cat = pd.get_dummies(df_cat, columns = [\"deposit_type\"])\n",
        "df_cat.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEk8fKMu6hXb"
      },
      "source": [
        "**Paso 20. TÃ©cnicas de muestreo:**\n",
        "Si el objetivo fuera predecir la variable is_canceled se deberia analizar el balance de cada una de las clases, a continuaciÃ³n se muestran en un grÃ¡ficos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af2CjuMU6kHs"
      },
      "outputs": [],
      "source": [
        "#Variable sÑ– la reserva fue cancelada o no\n",
        "sns.countplot(data=df, x = 'is_canceled')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8c3vxFW60sC"
      },
      "source": [
        "âž¡ï¸ Es evidente que hay mÃ¡s datos de una que de la otra, pudiera aplicarse una tÃ©cnicas de submuestreo para balancear las clases:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9sshGYMIxV4"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Contar las clases:\n",
        "count_class_No, count_class_Yes = df[\"is_canceled\"].value_counts()\n",
        "\n",
        "#Dividir los dataframes por las clases:\n",
        "df_class_No = df[df[\"is_canceled\"] == 0]\n",
        "df_class_Yes = df[df[\"is_canceled\"] == 1]\n",
        "\n",
        "#submuestrear la clase mayoritaria No:\n",
        "no_downsampled = resample(df_class_No,\n",
        "                      replace=False, # muestra sin reemplazo\n",
        "                      n_samples = count_class_Yes, # NÃºmero de muestras a generar\n",
        "\n",
        "                      random_state = 27) # resultados reproducibles\n",
        "                      #combinar dataframes\n",
        "df_sample = pd.concat([df_class_Yes, no_downsampled])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZimrrdj69JU"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df_sample, x = 'is_canceled')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHsxuhqnnNJf"
      },
      "source": [
        "**Consideraciones finales:**\n",
        "Suponiendo existe un atributo del dataframe df.precio con un formato similar a este $1,560.50 y queremos corregir el dato a tipo float\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjCJFA9onN5x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd1\n",
        "\n",
        "# Ejemplo de datos\n",
        "data = {'precio': ['$1,560.50', '$2,340.75', '$980.25']}\n",
        "df1 = pd1.DataFrame(data)\n",
        "print(\"Antes de la conversiÃ³n\")\n",
        "print(df1)\n",
        "\n",
        "# Convertir a float\n",
        "df1['precio'] = df1['precio'].str.replace('[\\$,]', '', regex=True).astype(float)\n",
        "print(\"DespuÃ©s de la conversiÃ³n\")\n",
        "print(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7m6wDPybxlV"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# MODELO DE REGRESIÃ“N: PredicciÃ³n del ADR\n",
        "# =====================================\n",
        "\n",
        "# !pip install sklearn\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# SelecciÃ³n de variables predictoras y target\n",
        "X = df.drop(columns=['adr', 'reservation_status', 'reservation_status_date'])\n",
        "y = df['adr']\n",
        "# X contiene todas las columnas potencialmente Ãºtiles menos aquellas que podrÃ­an sesgar el modelo\n",
        "# o contienen el target.\n",
        "\n",
        "# CodificaciÃ³n de variables categÃ³ricas\n",
        "X = pd.get_dummies(X, drop_first=True) # Convierte variables categÃ³ricas (tipo texto o categorÃ­as) en variables numÃ©ricas mediante One-Hot Encoding.\n",
        "# drop_first=True: elimina una de las categorÃ­as para evitar multicolinealidad (referencia redundante).\n",
        "# Es buena prÃ¡ctica para regresiÃ³n lineal.\n",
        "\n",
        "# DivisiÃ³n en train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un objeto imputador\n",
        "imputer = SimpleImputer(strategy='mean') # o 'mediana', 'mÃ¡s_frecuente'\n",
        "# Crea un objeto que puede reemplazar los valores faltantes (NaN) en el dataset.\n",
        "#strategy='mean': reemplazarÃ¡ los valores faltantes por la media de cada columna.\n",
        "\n",
        "# Ajuste el imputador a los datos de entrenamiento y transforme tanto los datos de entrenamiento como los de prueba\n",
        "X_train = imputer.fit_transform(X_train) # fit: calcula la media de cada columna en X_train.transform: reemplaza los valores faltantes en X_train con esa media.\n",
        "X_test = imputer.transform(X_test) #Se reemplazan los NaN en X_test con las medias calculadas en X_train.\n",
        "# Modelo de regresiÃ³n lineal\n",
        "reg_model = LinearRegression()\n",
        "# En lugar de utilizar X_train.index, utilice el Ã­ndice original de antes de la imputaciÃ³n\n",
        "reg_model.fit(X_train, y_train)\n",
        "y_pred = reg_model.predict(X_test)\n",
        "\n",
        "# EvaluaciÃ³n\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"RÂ²:\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9AK7HctE1xh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# =====================================\n",
        "# VisualizaciÃ³n de mÃ©tricas para el modelo de regresiÃ³n\n",
        "# =====================================\n",
        "\n",
        "# Realizar predicciones usando el modelo de regresiÃ³n\n",
        "y_pred_reg = reg_model.predict(X_test) # Asignar a y_pred_reg\n",
        "\n",
        "# GrÃ¡fico de dispersiÃ³n de valores predichos vs. reales\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred_reg, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)  # LÃ­nea de referencia\n",
        "plt.xlabel('Valor real')\n",
        "plt.ylabel('Valor predicho')\n",
        "plt.title('RegresiÃ³n: Valores predichos vs. reales')\n",
        "plt.show()\n",
        "\n",
        "# Histograma de residuos\n",
        "residuals = y_test - y_pred_reg\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(residuals, kde=True) # kde=True: agrega una curva de densidad suavizada (KDE = Kernel Density Estimation),\n",
        "#que ayuda a ver la forma general de la distribuciÃ³n.\n",
        "plt.xlabel('Residuos')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('RegresiÃ³n: Histograma de residuos')\n",
        "plt.show()\n",
        "\n",
        "# Imprimir mÃ©tricas\n",
        "print(\"RegresiÃ³n:\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred_reg))\n",
        "print(\"RÂ²:\", r2_score(y_test, y_pred_reg))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwdLZvwL1jQF"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# MODELO DE REGRESIÃ“N (Redes Neuronales): PredicciÃ³n del ADR\n",
        "# =====================================\n",
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, explained_variance_score, r2_score\n",
        "\n",
        "# SelecciÃ³n de variables predictoras y target\n",
        "X = df.drop(columns=['adr', 'reservation_status', 'reservation_status_date'])\n",
        "y = df['adr']\n",
        "\n",
        "# CodificaciÃ³n de variables categÃ³ricas\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# DivisiÃ³n en train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ImputaciÃ³n de valores faltantes\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# Escalar los datos (importante para redes neuronales)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define el modelo de red neuronal\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Capa entrada\n",
        "    tf.keras.layers.Dense(128, activation='relu'),  # Capa oculta 1\n",
        "    tf.keras.layers.Dense(64, activation='relu'),  # Capa oculta 2\n",
        "    tf.keras.layers.Dense(1)  # Capa salida (sin activaciÃ³n para la regresiÃ³n)\n",
        "])\n",
        "\n",
        "# Compila el modelo\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "#model.compile(optimizer='RMSprop', loss='mse')\n",
        "#model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "#model.compile(optimizer='adadelta', loss='mean_squared_error')\n",
        "#model.compile(optimizer='adagrad', loss='mean_squared_error')\n",
        "#model.compile(optimizer='adam', loss=tf.keras.losses.Huber())\n",
        "#model.compile(optimizer='adam', loss='log_cosh')\n",
        "#model.compile(optimizer='adam',loss='mean_squared_error', metrics=['mean_absolute_error', 'root_mean_squared_error'])\n",
        "\n",
        "\n",
        "# Entrena el modelo\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
        "\n",
        "# Realiza predicciones en el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse**0.5  # o usar mean_squared_error(y_test, y_pred, squared=False)\n",
        "medae = median_absolute_error(y_test, y_pred)\n",
        "explained_variance = explained_variance_score(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MAE:\", mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"MedAE:\", medae)\n",
        "print(\"Explained Variance:\", explained_variance)\n",
        "print(\"RÂ²:\", r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lrf0CymhCHU5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 1.Diagrama de dispersiÃ³n de valores previstos frente a valores reales\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)  # alfa para la transparencia\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)  # LÃ­nea diagonal\n",
        "plt.xlabel('ADR Real')\n",
        "plt.ylabel('ADR Predicho')\n",
        "plt.title('RegresiÃ³n de redes neuronales: ADR predicho vs. real')\n",
        "plt.show()\n",
        "\n",
        "# 2. Histograma de residuos (errores de predicciÃ³n)\n",
        "residuals = y_test - y_pred.flatten()  # Aplanar y_pred si es necesario\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(residuals, kde=True)  # kde para curva de densidad\n",
        "plt.xlabel('Residuos (Actual - Predicho)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('RegresiÃ³n de redes neuronales: DistribuciÃ³n Residual')\n",
        "plt.show()\n",
        "\n",
        "# 3. Imprimir las mÃ©tricas\n",
        "print(\"Neural Network Regression Metrics:\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"RÂ²:\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVL89zi-uaMM"
      },
      "outputs": [],
      "source": [
        "print (df['is_canceled'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af3n_Ac7qttb"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# MODELO DE CLASIFICACIÃ“N BINARIA (Redes Neuronales): CancelaciÃ³n de reserva\n",
        "# =====================================\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler  # Importar StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# SelecciÃ³n de variables predictoras y target\n",
        "X1 = df.drop(columns=['is_canceled', 'reservation_status', 'reservation_status_date'])\n",
        "# Define la variable objetivo correcta para la predicciÃ³n de cancelaciÃ³n\n",
        "y1 = df['is_canceled']\n",
        "\n",
        "# CodificaciÃ³n de variables categÃ³ricas\n",
        "X1 = pd.get_dummies(X1, drop_first=True)\n",
        "\n",
        "# DivisiÃ³n en train/test\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un objeto imputador\n",
        "imputer = SimpleImputer(strategy='mean') # o 'mediana', 'mÃ¡s_frecuente'\n",
        "# Crea un objeto que puede reemplazar los valores faltantes (NaN) en el dataset.\n",
        "#strategy='mean': reemplazarÃ¡ los valores faltantes por la media de cada columna.\n",
        "\n",
        "# Ajuste el imputador a los datos de entrenamiento y transforme tanto los datos de entrenamiento como los de prueba\n",
        "X_train1 = imputer.fit_transform(X_train1) # fit: calcula la media de cada columna en X_train.transform: reemplaza los valores faltantes en X_train con esa media.\n",
        "X_test1 = imputer.transform(X_test1) #Se reemplazan los NaN en X_test con las medias calculadas en X_train.\n",
        "\n",
        "# Escalar los datos (importante para redes neuronales)\n",
        "scaler = StandardScaler()\n",
        "X_train1 = scaler.fit_transform(X_train1)\n",
        "X_test1 = scaler.transform(X_test1)\n",
        "\n",
        "# Define el modelo de red neuronal using Input layer\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(X_train1.shape[1],)), # input_shape: define las dimensiones de entrada, que es el nÃºmero de variables predictoras (columnas en X_train).\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid') #Para clasificaciÃ³n binaria, la Ãºltima capa suele tener un solo nodo (neurona) con la funciÃ³n de activaciÃ³n sigmoidea\n",
        "])\n",
        "\n",
        "# Compila el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy', #PÃ©rdida para clasificaciÃ³n binaria.\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Ajustar learning_rate:\n",
        "# model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#model.compile(optimizer='adagrad', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['precision'])\n",
        "# O combinarlas:\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'precision', 'recall', 'f1_score'])\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
        "\n",
        "#Usar una funciÃ³n de pÃ©rdida ponderada:\n",
        "#from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Calcula los pesos de las clases\n",
        "#class_weights = compute_class_weight('balanced', classes=np.unique(y_train1), y=y_train1)\n",
        "#class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Compila el modelo con pesos de clase\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'], class_weight=class_weights)\n",
        "\n",
        "\n",
        "# Entrena el modelo\n",
        "model.fit(X_train1, y_train1, epochs=20, batch_size=32) # epochs: es el nÃºmero de veces que el modelo iterarÃ¡ (pasarÃ¡ por todos los datos de entrenamiento).batch_size: especifica el nÃºmero de ejemplos de entrenamiento utilizados en cada iteraciÃ³n del ciclo de entrenamiento.\n",
        "#model.fit(X_train1, y_train1, epochs=20, batch_size=64)\n",
        "\n",
        "# Realiza predicciones en el conjunto de prueba\n",
        "y_pred_probs = model.predict(X_test1)\n",
        "y_pred1 = (y_pred_probs > 0.5).astype(int) # Si la probabilidad de cancelaciÃ³n es superior al 0.5, se predice que la reserva se cancelarÃ¡ (1); de lo contrario, se predice que no se cancelarÃ¡ (0).\n",
        "\n",
        "# Evaluar el modelo (con manejo de la divisiÃ³n por cero)\n",
        "print(\"Accuracy:\", accuracy_score(y_test1, y_pred1))\n",
        "print(classification_report(y_test1, y_pred1, zero_division=1)) # maneja la divisiÃ³n por cero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zo86Io6xnf37"
      },
      "outputs": [],
      "source": [
        "# Visualizar la matriz de confusiÃ³n\n",
        "# Calcular la matriz de confusiÃ³n\n",
        "cm = confusion_matrix(y_test1, y_pred1)\n",
        "\n",
        "# Calcular los porcentajes\n",
        "total = np.sum(cm)\n",
        "percentages = (cm / total) * 100\n",
        "\n",
        "# Crear el mapa de calor con porcentajes (solo una llamada a heatmap)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            cbar=False)  # Eliminar barra de color para mÃ¡s espacio\n",
        "\n",
        "# Agregar anotaciones con porcentajes (dentro del mismo heatmap)\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j + 0.5, i + 0.3, f'{percentages[i, j]:.2f}%', # Desplazar hacia arriba\n",
        "                 ha='center', va='center', color='red', fontsize=8)\n",
        "\n",
        "\n",
        "plt.title('Matriz de precisiÃ³n con porcentajes')\n",
        "plt.ylabel('Clase real')\n",
        "plt.xlabel('Clase predicha')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}