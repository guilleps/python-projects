{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rM5z9ZAj1h-"
      },
      "source": [
        "Objetivo: Realizar todos los pasos dentro del proceso de preprocesamiento de datos sobre el conjunto de datos de Hotel Booking. El conjunto de datos contiene información sobre reservas de hotel realizadas en dos hoteles, uno en ciudad y otro un resort.\n",
        "Cada fila consiste en una reserva del hotel.\n",
        "Incluye información sobre cuando fue realizada.\n",
        "La duración de la estadía.\n",
        "El número de adultos, niños y bebés entre otras cosas.\n",
        "Este conjunto de datos es ideal para practicar el análisis exploratorio de los datos y los conceptos de limpieza y calidad de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jjyzpdKkF46"
      },
      "source": [
        "**Paso 1. Importamos las librerías:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aqJ1bX7jowa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "import plotly.express as px\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42-gI0QYmEyM"
      },
      "source": [
        "**Paso 2. Cargamos los datos:**\n",
        "El conjunto de datos se encuentran en formato CSV (valores separados por comas).\n",
        "Existen diferentes formas de cargar el conjunto de datos, se puede cargar desde una dirección URL o desde nuestro google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeZwsPawmFLJ"
      },
      "outputs": [],
      "source": [
        "#drive.mount('/content/drive')\n",
        "#csv_path = \"/content/drive/MyDrive/hotel_bookings.csv\"\n",
        "#df = pd.read_csv(csv_path)\n",
        "df = pd.read_csv('hotel_bookings.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvT0oyRpoNj7"
      },
      "source": [
        "**Paso 3. Conociendo los datos:**\n",
        "Para comenzar a conocer los datos podemos utilizar dos métodos que nos ayudaran a obtener un vistazo rápido del conjunto de datos, se utilizan los comandos:\n",
        "\n",
        "dataframe.shape indica el número de filas y columnas.\n",
        "dataframe.info indica el número de filas, columnas y el nombre de las columnas, cuenta el número de nulos y muestra de tipo de dato de cada columna y su cantidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRh8ZhINoOgB"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PrC1d_4orRP"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKqglxjBo4Pv"
      },
      "source": [
        "**Paso 4. Identificar los tipos de datos:**\n",
        "Exploramos los tipos de datos de cada columna. Así mismo, identificaremos si hay alguna columna que según su significado no coincida con su tipo de dato:\n",
        "\n",
        "La función dtypes genera una tabla con el tipo de dato de cada columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vMmx5A8o7LP"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spB_KoASpoKM"
      },
      "source": [
        "Observamos que si hay columnas que según su significado no coincide con su tipo de dato, como por ejemplo, la columna children, presenta como tipo de dato float, sin embargo, debería de ser int. De igual manera con la columna, reservation_status_date, debería de ser datetime64\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6NxYScdpwys"
      },
      "source": [
        "**Paso 5. Identificar datos faltantes:**\n",
        "Para identificar los datos faltantes en el conjunto de datos se puede utilizar la función isnull y sumar los valores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LTL1xNOpo5d"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS-eOwRMp8QA"
      },
      "source": [
        "Observamos que la columna company presenta más del 50% de datos faltantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtHKggGZqDAr"
      },
      "source": [
        "**Paso 6. Identificar datos atípicos:**\n",
        "Para identificar datos atípicos se pueden utilizar distintos métodos, Utilicemos un gráfico de box plot para graficar una de las variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AauFshuUp9CS"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "sns.boxplot(y=df[\"stays_in_weekend_nights\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3Ed_e-lqfWa"
      },
      "source": [
        "Observamos que la mayoría de huespedes se quedan hasta cinco noches de fin de semana.\n",
        "➡️ También se pueden analizar los datos utilizando alguna variable categórica, por ejemplo, las reservas canceladas o no canceladas y vincularlo a una variable numérica como las noches de fin de semana:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su201xXIqf6p"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8,9))\n",
        "sns.boxplot(x=\"is_canceled\", y=\"stays_in_weekend_nights\", data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atV9APj1rZSH"
      },
      "source": [
        "**Paso 7. Calcular las estadísticas:**\n",
        "dataframe.describe para visualizar las estadísticas del conjunto de datos. Por defecto, la función describe trabaja con columnas numéricas y no con columnas de tipo object, mostrando los siguientes datos:\n",
        "\n",
        "El número de elementos de la variable\n",
        "La media\n",
        "La desviación estándar (std)\n",
        "El valor mínimo\n",
        "Los cuartiles\n",
        "El valor máximo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_0eeX_krbOu"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1y6fgMIrljl"
      },
      "source": [
        "➡️ Ahora visualizamos a las variables categóricas: agregándole include=['object'] podremos observar solo las columnas que son categóricas (de tipo object):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWpZ71gSrq-U"
      },
      "outputs": [],
      "source": [
        "df.describe(include=['object'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWG0_ADIr4ND"
      },
      "source": [
        "unique: para saber cuantos valores son únicos, como podemos ver en la columna hotel hay 2 valores diferentes.\n",
        "top: para ver el valor que más se repite, el cual es City Hotel.\n",
        "freq: la frecuencia en que se repide el valor City Hotel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceALLIebsLAC"
      },
      "source": [
        "**Paso 8. Análisis de tendencia central, posición y dispersión:** 🎯\n",
        "El análisis de la tendencia central, la simetría y la dispersión de los datos es importante para entender cómo se comporta cada variable:\n",
        "\n",
        "➡️ lead_time: número de días entre hecha la reserva y el día de llegada al hotel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKuPxaK9sSLa"
      },
      "outputs": [],
      "source": [
        "df['lead_time'].hist(figsize = (6,6))\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJVi-3QxsnYS"
      },
      "source": [
        "Este gráfico muestra un sesgo positivo hacia la derecha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3JSPd1Vsr4o"
      },
      "outputs": [],
      "source": [
        "mean = df['lead_time'].mean()\n",
        "median = df['lead_time'].median()\n",
        "mode = df['lead_time'].mode()\n",
        "skew = df['lead_time'].skew()\n",
        "kurt = df['lead_time'].kurt()\n",
        "\n",
        "print(\"La media es:\", mean)\n",
        "print(\"La mediana es:\", median)\n",
        "print(\"La moda es:\", mode)\n",
        "print(\"El sesgo es:\", skew)\n",
        "print(\"La kurtosis es:\", kurt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InBQ47myszwI"
      },
      "source": [
        "➡️ arrival_date_week_number: número de la semana del año en que llega el huesped al hotel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV3CGVd2s55G"
      },
      "outputs": [],
      "source": [
        "df['arrival_date_week_number'].hist(figsize = (6,6))\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7MDUSy9tIkQ"
      },
      "outputs": [],
      "source": [
        "mean = df['arrival_date_week_number'].mean()\n",
        "median = df['arrival_date_week_number'].median()\n",
        "mode = df['arrival_date_week_number'].mode()\n",
        "skew = df['arrival_date_week_number'].skew()\n",
        "kurt = df['arrival_date_week_number'].kurt()\n",
        "\n",
        "print(\"La media es:\", mean)\n",
        "print(\"La mediana es:\", median)\n",
        "print(\"La moda es:\", mode)\n",
        "print(\"El sesgo es:\", skew)\n",
        "print(\"La kurtosis es:\", kurt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF_islZJszsw"
      },
      "source": [
        "**Paso 9. Contando datos duplicados:**\n",
        "Para ver los datos duplicados del conjunto de datos llamamos al método duplicated() en el DataFrame. Si luego llamamos al método SUM, obtendremos el total de duplicados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLDAI0mXtS5d"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_CSb2G6tXeN"
      },
      "source": [
        "Observamos que existen 31994 filas con los mismos datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmtojmWqtbTV"
      },
      "source": [
        "**Paso 10. Exploración y visualización de los datos:**\n",
        "Utilizando tecnicas de visualización se puede comenzar a comprender el contexto alrededor de los datos, se van a realizar diferentes preguntas capaces de brindar información interesante.\n",
        "\n",
        "Estas preguntas nos ayudan a encontrar análisis significativos sin siquiera aplicar alguna técnica de analítica.\n",
        "Se comprende mejor el mundo de las reservas de hoteles, así como las necesidades que les pueden surgir a las empresas y que se tratan de solucionar con herramientas analíticas.\n",
        "Empezaremos a analizar las variables numéricas y luego las categóricas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftLuwreEtnl8"
      },
      "source": [
        "**10.1. Análisis de variables numéricas:**\n",
        "Explorando las variables numéricas observamos su distribución. Se puede utilizar el diagrama de hist para visualizar todos los histogramas de las variables numéricas dentro del dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m78RlGSthIU"
      },
      "outputs": [],
      "source": [
        "df.hist(figsize=(20,15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lb0KX-gtylj"
      },
      "source": [
        "➡️ También se puede analizar cada variable de manera independiente. En este gráfico se muestra el histograma de la variable arrival_Date_week_number que muestra las diferentes semanas del año 1-52, donde los clientes reservan o se hospedan en los hoteles:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqcbPC52t_sC"
      },
      "outputs": [],
      "source": [
        "df['arrival_date_week_number'].hist(figsize = (6,6))\n",
        "plt.xlabel('arrival_date_week_number')\n",
        "plt.ylabel('Cantidad')\n",
        "plt.title('Histograma arrival_date_week_number', fontweight = \"bold\")\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrGbCzjquFLK"
      },
      "source": [
        "➡️ En este histograma se aprecia la distribución de la variable adr (tarifa diaria promedio):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vhm5XuHuJDR"
      },
      "outputs": [],
      "source": [
        "df['adr'].hist(figsize = (6,6))\n",
        "plt.xlabel('Average Daily Rate')\n",
        "plt.ylabel('Cantidad')\n",
        "plt.title('Histograma adr', fontweight = \"bold\")\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlhPZb22uSKK"
      },
      "source": [
        "➡️ Para visualizar la relación entre dos variables numéricas se utiliza un gráfico de líneas. Este combina las variables de mes de llegada arrival_date_month y tarifa promedio adr. Como tenemos variables que representan tiempo (años, meses, semanas, fecha) se puede realizar un análisis en el tiempo para ver su comportamiento. La temporada alta es junio, julio, agosto y la temporada baja es noviembre, diciembre y enero:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV4SrgwUuXMq"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(7,4), dpi=100)\n",
        "plt.xticks(rotation = 45, fontsize=10)\n",
        "sns.lineplot(data=df, x = 'arrival_date_month', y = 'adr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wVwJKBPuhLw"
      },
      "source": [
        "➡️ Ahora hacemos lo mismo, pero con el número de semana del año arrival_date_week_number:\n",
        "\n",
        "Vemos que el gráfico coincide, ya que el número de semana coincide con el mes del año."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPFgXUsduitE"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(7,4), dpi=100)\n",
        "plt.xticks(rotation = 45, fontsize=10)\n",
        "sns.lineplot(data=df, x = 'arrival_date_week_number', y = 'adr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmOYfXqnuo-p"
      },
      "source": [
        "**10.2. Análisis de variables categóricas:**\n",
        "Para analizar las variables categóricas, seleccionamos primero el subconjunto del dataframe y visualizamos los valores de cada categoría. Identificamos algún valor que no corresponda con el negocio.\n",
        "\n",
        "Seleccionar las variables categóricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t26ca1iuvNA"
      },
      "outputs": [],
      "source": [
        "df_cat = df.select_dtypes(include=['object'])\n",
        "df_cat.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8niDKk5u0-n"
      },
      "source": [
        "La columna reservation_status_date se muestra como tipo de dato categórico, sin embargo, debería de ser datetime64 más adelante se hará el cambio.\n",
        "➡️ Visualizar los valores de cada una de las variables:\n",
        "\n",
        "Esto nos ayuda a identificar valores que no coinciden con el dominio del negocio, de ser así, lo eliminaríamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v-D7GiHu6hZ"
      },
      "outputs": [],
      "source": [
        "for col in df_cat.columns:\n",
        "  print(f\"{col}: \\n{df_cat[col].unique()}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc_G5Wq8vM7O"
      },
      "source": [
        "➡️ Ahora, utilizando gráficos se observa la proporción entre las distintas categorías.\n",
        "\n",
        "Gráfico que muestra a la variable si la reserva fue cancelada o no:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dluiBG-vOMt"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df, x = 'is_canceled')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvJ7CHLBvdYm"
      },
      "source": [
        "➡️ Inclinación de los clientes por los distintos tipos de habitación:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uH-gOqMjvevW"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df, x = 'reserved_room_type')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlYbXA8WvmB8"
      },
      "source": [
        "Observamos que el tipo de habitación A es la que más se ha reservado.\n",
        "➡️ Por dónde se realizaron las reservas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnCeqZmdvm_U"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df, x= 'market_segment')\n",
        "plt.xticks(rotation=45, fontsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywCaYzVkv11j"
      },
      "source": [
        "Observamos que la mayoría de reservas se hicieron por Online TA.\n",
        "➡️ Análisis de las reservas que no fueron canceladas, según el segmento del mercado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlSi5MAaxBpX"
      },
      "outputs": [],
      "source": [
        "#Separamos los grupos por tipo de hotel y solo con reservas no canceladas:\n",
        "rh = pd.DataFrame(df.loc[(df['hotel'] == 'Resort Hotel') & (df['is_canceled'] == 0)])\n",
        "ch = pd.DataFrame(df.loc[(df['hotel'] == 'City Hotel') & (df['is_canceled'] == 0)])\n",
        "\n",
        "#Ajustamos tamaño de la figura:\n",
        "fig = plt.figure(figsize = (16, 9))\n",
        "\n",
        "#Pie de Resort Hotel:\n",
        "ax = fig.add_subplot(121)\n",
        "rh_segment_pie = pd.DataFrame(rh['market_segment'].value_counts())\n",
        "ax.set_title('The Market segment of Resort Hotel', fontsize = 14)\n",
        "# rh_segment_pie['market_segment'] does not exist, it is actually in the index\n",
        "# Use rh_segment_pie['count'] instead to access the values for the pie chart\n",
        "# and rh_segment_pie.index to access the labels\n",
        "ax.pie(x = rh_segment_pie['count'], labels = rh_segment_pie.index, autopct = '%.3f%%')\n",
        "\n",
        "#Pie de City Hotel:\n",
        "ax = fig.add_subplot(122)\n",
        "ch_segment_pie = pd.DataFrame(ch['market_segment'].value_counts())\n",
        "ax.set_title('The Market segment of City Hotel', fontsize = 14)\n",
        "# Similarly, use ch_segment_pie['count'] for the values and ch_segment_pie.index for the labels\n",
        "ax.pie(x = ch_segment_pie['count'], labels = ch_segment_pie.index, autopct = '%.3f%%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsqXd0-CxXmo"
      },
      "source": [
        "**Paso 11. Combinando variables:**\n",
        "Después de analizar las variables de manera individual para comprender su comportamiento, se pueden encontrar relaciones interesantes entres dos, tres o cuatro variables. A continuación se responden algunas preguntas interesantes:\n",
        "\n",
        "➡️ ¿Qué tipo de hotel tiene el mayor número de cancelaciones?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kewdVBCvxb44"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df, x = 'hotel', hue='is_canceled')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TudQbIZUxjn4"
      },
      "source": [
        "➡️ ¿Cuáles son los paises más visitados?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Upur-aIBxnUA"
      },
      "outputs": [],
      "source": [
        "paises_mas_visitas = df[df['is_canceled'] == 0]['country'].value_counts().reset_index()\n",
        "paises_mas_visitas.columns = ['country', 'No of guests']\n",
        "paises_mas_visitas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWoc6ZxExwfO"
      },
      "source": [
        "➡️ Mapa para visualizar los paises anteriores y la cantidad de visitantes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpNUWoB5x0IG"
      },
      "outputs": [],
      "source": [
        "basemap = folium.Map()\n",
        "guests_map = px.choropleth(\n",
        "    paises_mas_visitas,\n",
        "    locations = paises_mas_visitas['country'],\n",
        "    color_continuous_scale=\"portland\",\n",
        "    color = paises_mas_visitas['No of guests'],\n",
        "    hover_name = paises_mas_visitas['country']\n",
        ")\n",
        "\n",
        "guests_map.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8acAqVt1x-xs"
      },
      "source": [
        "➡️ ¿Cuánto se paga por una noche de alojamiento?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDpkCSY5yDCC"
      },
      "outputs": [],
      "source": [
        "# Filtramos las reservas no canceladas\n",
        "cuanto_se_paga = df[df['is_canceled'] == 0]\n",
        "plt. figure (figsize= (12,8))\n",
        "\n",
        "sns.boxplot(x='reserved_room_type', y='adr', data=cuanto_se_paga, hue='hotel')\n",
        "plt.title('Precio por tipo de habitación por noche', fontsize=16)\n",
        "plt.xlabel('Tipo de Habitación')\n",
        "plt.ylabel('Precio en [EUR]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zIcbCi7yPTk"
      },
      "source": [
        "➡️ ¿Existe alguna relación entre el número de días transcurridos desde la reserva y las cancelaciones?\n",
        "\n",
        "lead_time: num días transcurridos entre la fecha de reserva y el dia de llegada al hotel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaV_Ygx4ySgz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize= (12, 6))\n",
        "sns.barplot(x='arrival_date_year', y='lead_time', hue='is_canceled', data = df)\n",
        "plt.title ('Alo de llegada, Anticipo y Cancelaciones')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AS0N_D5yZ73"
      },
      "source": [
        "➡️ ¿Se distribuyen de forma homogénea las llegadas dependiendo del mes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH1nP-VVydzD"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15,6))\n",
        "sns.countplot(data = df, x = 'arrival_date_day_of_month', hue = 'hotel')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIicCa1dynRb"
      },
      "source": [
        "Se concluye que se distribuyen de forma razonablemente homogenea. El valor más bajo se registra los días 31, esto se debe a que no todos los meses tienen 31 días y por tanto el recuento de llegadas es inferior.\n",
        "➡️ ¿Qué tipo de régimen de pensión eligen los huéspedes?\n",
        "\n",
        "SC: No meal\n",
        "BB: Bed and Breakfast\n",
        "HB: Half board\n",
        "FB: Full board (pensión completa)\n",
        "Undefined: No definido el régimen de comida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7Uj34S4yoqr"
      },
      "outputs": [],
      "source": [
        "meal_labels = ['BB','B', 'SC', 'Sin definir', 'FB']\n",
        "size = df['meal'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "cmap = plt.get_cmap(\"Pastel2\")\n",
        "colors = cmap(np.arange(6)*1)\n",
        "my_circle = plt.Circle((0,0), 0.7, color = 'white')\n",
        "\n",
        "plt.pie(size, labels=meal_labels, colors=colors, wedgeprops = {'linewidth' : 3, 'edgecolor' : 'white' })\n",
        "p=plt.gcf()\n",
        "p.gca().add_artist(my_circle)\n",
        "plt.title('Tipo de régimen', weight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrnPDl4Fy6-x"
      },
      "source": [
        "La mayoría de las reservas son con régimen de cama de desayuno (Bed & Breakfast) y sólo una parte muy pequeña elije pensión completa (Full Board)\n",
        "➡️ Se puede analizar el comportamiento de un país en específico, utilicemos España como ejemplo:\n",
        "\n",
        "Cantidad de reservas en España"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt9dwbe9y8hI"
      },
      "outputs": [],
      "source": [
        "reservation_date_Spain = df[df['country'] == \"ESP\"][df['is_canceled'] == 0]['arrival_date_year'].value_counts().reset_index()\n",
        "reservation_date_Spain.columns = ['Año', 'N° Reservas']\n",
        "reservation_date_Spain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCBlLYT_zDZZ"
      },
      "source": [
        "Se visualizan los resultados de España:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmJ9pxjozGh5"
      },
      "outputs": [],
      "source": [
        "sns.barplot(x = \"Año\", y = \"N° Reservas\", data = reservation_date_Spain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wb53fyTzWog"
      },
      "source": [
        "➡️ Ahora analizamos el comportamiento de la cantidad de reservas en Perú:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te3EfMwJzbSB"
      },
      "outputs": [],
      "source": [
        "reservation_date_Peru = df[df['country'] == \"PER\"][df['is_canceled'] == 0] ['arrival_date_year'].value_counts().reset_index()\n",
        "reservation_date_Peru.columns = ['Año', 'N° Reservas']\n",
        "reservation_date_Peru"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsJ_sORezjpn"
      },
      "source": [
        "➡️ Se visualizan los resultados de Perú:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx7LhpD9zi-u"
      },
      "outputs": [],
      "source": [
        "sns.barplot(x = \"Año\", y = \"N° Reservas\", data = reservation_date_Peru)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R1NE8fHzsYf"
      },
      "source": [
        "➡️ ¿Cuál es el país con más hoteles y de qué tipo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9O4S4j3zvhu"
      },
      "outputs": [],
      "source": [
        "counts = df['country'].value_counts()\n",
        "plt.subplots(figsize = (10, 5))\n",
        "sns.countplot(x= 'country', hue='hotel', data=df[df['country'].isin(counts[counts > 2000].index)])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saPhWkthz7wl"
      },
      "outputs": [],
      "source": [
        "counts = df['country'].value_counts()\n",
        "counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv9hxJOS0DTf"
      },
      "source": [
        "➡️ Analizamos la relación entre las variables “Deposit type” y “is_canceled”:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlXU1wAq0Eq9"
      },
      "outputs": [],
      "source": [
        "deposit_cancel_data = df.groupby(\"deposit_type\")[\"is_canceled\"].describe()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=deposit_cancel_data.index, y=deposit_cancel_data [\"mean\"] * 100)\n",
        "plt.title(\"Influencia del depósito en la cancelación\", fontsize=16)\n",
        "plt.xlabel(\"Tipo de depósito\", fontsize=16)\n",
        "plt.ylabel(\"Cancelaciones [%]\", fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND1HknDC0MLM"
      },
      "source": [
        "➡️ De este análisis exploratorio de los datos se puede concluir lo siguiente:\n",
        "\n",
        "La indudable importancia de la variable hotel, referida al tipo de hotel que se está reservando, pues como hemos podido ver en varios gráficos, la diferencia en la interpretación es considerable cuando hablamos de un resort frente a un hotel de ciudad.\n",
        "Por otro lado, las peculiaridades en ciertas variables como “lead_time”, “Booking_changes” y “previous_cancellations”, las cuales se considera que pueden tener un peso considerable para predecir de una manera más precisa futuras cancelaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTCFIHfiz2vW"
      },
      "source": [
        "**Paso 12. Limpieza de datos:**\n",
        "Resolveremos problemas de calidad\n",
        "➡️ Resolver problema de datos faltantes, observemos qué variables tienen datos faltantes y qué se puede hacer en cada caso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC_J766v0QGF"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D5_bmNw0kGC"
      },
      "outputs": [],
      "source": [
        "df[[\"children\", \"country\", \"agent\", \"company\"]].describe(include=\"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USYbu9-t0ggc"
      },
      "source": [
        "➡️ La cantidad de datos faltantes en la columna company hace que no sea útil sustituirlos o imputarlos, pues faltan muchos datos y modificarlos supondría una grave alteración de los datos.\n",
        "\n",
        "➡️ La columna agent no está en la misma situación pero no aporta gran valor pues solo es el identificador de los agentes, no el nombre en si. Por tanto se procede a eliminar esas variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kVUuiXY0veK"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['company', 'agent'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0TTmNJA013i"
      },
      "source": [
        "➡️ Para trabajar las columnas country y children una alternativa es eliminar los registros que tienen NA:\n",
        "\n",
        "A modo de ejemplo lo eliminamos, pero lo almacenamos en otro DataFrame (df1):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9JhaHbK04BC"
      },
      "outputs": [],
      "source": [
        "df1 = df.dropna (subset=['country', 'children'], axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xFGJGwJiiyn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA8vIzF309B5"
      },
      "outputs": [],
      "source": [
        "print(df1.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cySP8Yv21HO5"
      },
      "source": [
        "➡️ Otra alternativa es sustituir la variable con un valor.\n",
        "\n",
        "Para la columna country que es categórica sería sustituir con la Moda.\n",
        "El país más común es PRT (Portugal). Por ello, sustituímos por PRT a los datos faltantes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWfy6MEz1Ijv"
      },
      "outputs": [],
      "source": [
        "df[\"country\"].replace(np.nan, \"PRT\", inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRjN_jeM1iQX"
      },
      "source": [
        "Para la variable children que es numérica sería necesario analizar su simetría y luego sustituir con su media o mediana:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSAk5tiy1lve"
      },
      "outputs": [],
      "source": [
        "sns.displot(df[\"children\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch1icRwB1uHe"
      },
      "outputs": [],
      "source": [
        "mean = df['children'].mean()\n",
        "median = df['children'].median()\n",
        "mode = df['children'].mode()\n",
        "skew = df['children'].skew()\n",
        "kurt = df['children'].kurt()\n",
        "\n",
        "print(\"La media es:\", mean)\n",
        "print(\"La mediana es:\", median)\n",
        "print(\"La moda es:\", mode)\n",
        "print(\"El sesgo es:\", skew)\n",
        "print(\"La kurtosis es:\", kurt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77nKcIOX1qcO"
      },
      "source": [
        "➡️ A los datos faltantes lo sustituímos por 0, porque su mediana es 0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA1vGRKF11Hf"
      },
      "outputs": [],
      "source": [
        "df[\"children\"].replace(np.nan, 0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdKvX6bJ2Gmk"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5NssUcB2CHN"
      },
      "source": [
        "**Paso 13. Tipos de datos:**\n",
        "La columna children tiene como tipo de dato float, pero debería ser int, entonces procedemos a cambiarle su tipo de dato, lo mismo hacemos para la columna reservation_status_date lo cambiamos de tipo object a DateTime:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSuc9miA2O7M"
      },
      "outputs": [],
      "source": [
        "df[[\"children\"]] = df[[\"children\"]].astype(\"int\")\n",
        "df['reservation_status_date'] = pd.to_datetime(df['reservation_status_date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9DOET4a2XLD"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqYnUwer2ey0"
      },
      "source": [
        "**Paso 14. Datos inconsistentes:**\n",
        "Al analizar las caracteristicas de las reservas, en concreto en lo que se refiere a los huéspedes, se puede observar que existen registros que cumplen con la condición de que: (data.children == 0) & (data.adults == 0) & (data.babies == 0)\n",
        "No puede haber O’s en una misma observación en adults, children y babies (no se puede hacer una reserva sin huéspedes).\n",
        "Estos registros se deben eliminar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiM-eq3X2ge0"
      },
      "outputs": [],
      "source": [
        "filter = (df.children == 0) & (df.adults == 0) & (df.babies == 0)\n",
        "sum(filter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZurSpxOA2oGF"
      },
      "source": [
        "➡️ Se concluye que se trata de un error, por lo que se procede a eliminarlos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz-uI8WB2sKV"
      },
      "outputs": [],
      "source": [
        "df = df[~filter]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUNQMp9S2xii"
      },
      "source": [
        "➡️ Comprobación de que no hay registros que sumen cero y por tanto el número de registros total es correcto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNOoAsvQ223y"
      },
      "outputs": [],
      "source": [
        "#Total de huéspedes:\n",
        "df['Total_Guests'] = df['adults'] + df['children']\n",
        "\n",
        "#Comprobamos que efectivamente no hay ningún registro que sume 0:\n",
        "filter = df.Total_Guests != 0\n",
        "df.drop(\"Total_Guests\", axis=1, inplace=True)\n",
        "sum(filter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au-kw0yv211y"
      },
      "source": [
        "df.drop(\"Total_Guests\", axis=1, inplace=True): Eliminamos la columna porque solo era para probar\n",
        "El número de registros total son 119210, asi que es correcto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvtPNzyM3HcZ"
      },
      "source": [
        "**Paso 15. Datos atípicos:**\n",
        "Se comienza con la detección de outliers visualizando los boxplot de las diferentes variables que conforman nuestro modelo. De su visualización obtenemos un total de 8 variables que presentan cierta problemática: ‘lead time’, ‘stays in weekend nights’, ‘stays in week nights, ‘adults’, “babies’, ‘required car parking spaces’, ‘adr, ‘previous cancellations’."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMuaE8Jg3CiY"
      },
      "outputs": [],
      "source": [
        "columnas = ['lead_time', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults',\n",
        "            'babies', 'required_car_parking_spaces', 'adr', 'previous_cancellations']\n",
        "n = 1\n",
        "plt.figure(figsize = (20, 15))\n",
        "\n",
        "for column in columnas:\n",
        "  plt.subplot(4, 4, n)\n",
        "  n = n + 2\n",
        "  sns.boxplot (y=df[column])\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6gorFRA3BfC"
      },
      "source": [
        "➡️ Se procede a sustituir la mayoria de los valores atípicos por otros dentro del último cuartil o por el valor cero dependiendo del caso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G96HY4dS3gQr"
      },
      "outputs": [],
      "source": [
        "df.loc[df.lead_time > 400, 'lead time'] = 400\n",
        "df.loc[df.stays_in_weekend_nights >= 5, 'stays_in_weekend_nights'] = 5\n",
        "df.loc[df.stays_in_week_nights > 20, 'stays_in_week_nights'] = 20\n",
        "df.loc[df.adults > 10, 'adults'] = 10\n",
        "df.loc[df.babies > 8, 'babies'] = 0\n",
        "df.loc[df.required_car_parking_spaces > 5, 'required_car_parking_spaces'] = 0\n",
        "df.loc[df.adr > 1000, 'adr'] = 1000\n",
        "df.loc[df.adr < 30, 'adr'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udplcCpn3n53"
      },
      "outputs": [],
      "source": [
        "df['adr'].plot(kind = 'hist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcXNxUVy3tU_"
      },
      "source": [
        "➡️ Cuando se quiere analizar todas las variables para saber si hay registros atípicos e inconsistentes entre ellas, se puede utilizar el algoritmo de LOF. Para el ejemplo se utiliza una selección de las variables numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQNFrHFp3uR_"
      },
      "outputs": [],
      "source": [
        "#Seleccionar columnas:\n",
        "select_df = df[['lead_time', 'arrival_date_year', 'stays_in_weekend_nights', 'adults',\n",
        "                'is_repeated_guest', 'previous_cancellations', 'required_car_parking_spaces',\n",
        "                'adr']]\n",
        "\n",
        "#Especificar el modelo que se va a utilizar:\n",
        "model = LocalOutlierFactor(n_neighbors = 30)\n",
        "\n",
        "#Ajuste al modelo:\n",
        "y_pred = model.fit_predict(select_df)\n",
        "y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUyj-9Z_38WF"
      },
      "outputs": [],
      "source": [
        "#Filtrar los indices de los outliers\n",
        "outlier_index = (y_pred == - 1) #los valores negativos son outliers\n",
        "\n",
        "#Filtrar los valores de los outliers en el dataframe\n",
        "outlier_values = select_df.iloc[outlier_index]\n",
        "outlier_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsosmlqQ4Cj-"
      },
      "source": [
        "Se obtuvieron 6397 muestras como atípicos, si se aplica una técnica basado en distancias, es importante eliminar los datos atípicos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbUxoS0n4HN1"
      },
      "source": [
        "**Paso 16. Datos redundantes:**\n",
        "Para identificar los atributos redundantes se pueden utilizar la matriz de correlación e indentificar correlaciones entre atributos.\n",
        "La matriz de correlación solo se calcula sobre atributos numéricos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkV3-S4s4Slk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (24, 12))\n",
        "# Select only numeric features for correlation calculation\n",
        "numeric_df = df.select_dtypes(include=['number'])\n",
        "corr = numeric_df.corr()\n",
        "sns.heatmap(corr, annot = True, linewidths = 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oFsjTWu4hQT"
      },
      "source": [
        "**Paso 17. Datos duplicados:**\n",
        "El anális de datos duplicados en este conjunto es interesante.\n",
        "\n",
        "Existen muchas filas duplicadas, sin embargo en algunos casos pudieran ser coincidencias de reservas iguales, para clientes diferentes.\n",
        "En este caso es mejor indagar un poco en el negocio para saber cual es realmente la posibilidad de reservas identicas.\n",
        "En último recursos, si se eliminan todos los duplicados, quedarían aún suficientes datos para realizar un análisis interesante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWxmU8uQ4ij0"
      },
      "outputs": [],
      "source": [
        "#Contando los duplicados de todo el dataframe:\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfOSpCVT4rjV"
      },
      "outputs": [],
      "source": [
        "#Permite ver las filas duplicadas de todo el dataframe\n",
        "df.loc[df.duplicated(), :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLkRNV2l45Q6"
      },
      "outputs": [],
      "source": [
        "#Si se quisiera eliminar los duplicados\n",
        "df_drop = df.drop_duplicates()\n",
        "df_drop.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr7f1LyD4n5D"
      },
      "source": [
        "**Paso 18. Transformaciones a los datos:**\n",
        "Las transformaciones que se van a aplicar a continuación dependen de la técnica analitica a aplicar. No siempre es necesario aplicarlas todas. En este notebook se aplicarán todas a manera de ejemplo.\n",
        "Es importante tener claras las necesidades de cada técnica para aplicar lo más adecuado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeToeJU6GMd-"
      },
      "source": [
        "**18.1. Normalización:**\n",
        "La normalización o escalamiento es necesario para poner todas las variables numéricas en la misma escala.\n",
        "Las técnicas basadas en distancias siempre necesitan normalización. A continuación se normalizan las variales numéricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1eKQ9Me5A76"
      },
      "outputs": [],
      "source": [
        "df_normalize = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZHY4n895EVp"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "df_normalize[['lead_time', 'arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
        "              'stays_in_week_nights', 'adr']] = scaler.fit_transform(df_normalize[['lead_time',\n",
        "              'arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adr']])\n",
        "\n",
        "df_normalize[['lead_time', 'arrival_date_year', 'arrival_date_day_of_month', 'stays_in_weekend_nights',\n",
        "              'stays_in_week_nights', 'adr']].tail(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw2Ec6L85JKS"
      },
      "source": [
        "**18.2. Discretización:**\n",
        "Para realizar un ejemplo de discretización se utiliza la variable lead_time que significa los días de antelación con la que se realiza una reserva. Primero se visualiza la distribución de la variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nijW-Fqv5MnR"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "sns.boxplot(y=df[\"lead_time\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOfAhObX5XJz"
      },
      "source": [
        "➡️ A continuación se diseñan los grupos (bins) por los cuales se desea discretizar la variable y se realiza la discretización:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emrIMz1G5YVK"
      },
      "outputs": [],
      "source": [
        "nivelAntelacion = ['Ninguno', '2-3Semanas', '1Mes', '2Meses', '3Meses', 'Mas3Meses']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-8zSgbX5gw3"
      },
      "outputs": [],
      "source": [
        "df['lead_time_binned'] = pd.cut(x = df['lead_time'],\n",
        "                      bins = [0, 1, 21, 30, 60, 120, 737],\n",
        "                      labels = nivelAntelacion, include_lowest = True)\n",
        "df[['lead_time', 'lead_time_binned']].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhq9ovrK5oDX"
      },
      "source": [
        "➡️ Una vez discretizada la variable se visualizan los resultados, se puede observar que la mayor proporsión de ejemplos permanecen en la categorias de Mas3Meses. Tambien se analiza cómo se comportan las cancelaciones con respecto a la nueva variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_Pvdr0z5pGn"
      },
      "outputs": [],
      "source": [
        "sns.catplot(x=\"lead_time_binned\", kind=\"count\", data=df, height = 6, aspect = 1.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BlY6dJY5y-f"
      },
      "outputs": [],
      "source": [
        "sns.catplot(x=\"lead_time_binned\", hue = 'is_canceled', kind=\"count\", data=df, height = 6, aspect = 1.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e-nxbkS52N_"
      },
      "source": [
        "**Paso 19. Numerización:**\n",
        "El objetivo de numerizar es convertir a número distintas variables que son categóricas, esto puede ser muy necesario para ciertas técnicas que solo funcionan con datos numéricos. A continuación se muestra cómo numerizar distintas variables del conjunto de datos según su tipo y valor.\n",
        "Las siguientes variables se pueden numerizar 1 a 1, esto significa que podemos sustituir los valores por números:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqJN8Cp-55zi"
      },
      "outputs": [],
      "source": [
        "# Numerizar 1 a 1\n",
        "df_cat['hotel'] = df_cat['hotel'].map({'Resort Hotel' : 0, 'City Hotel' : 1})\n",
        "df_cat['reserved_room_type'] = df_cat['reserved_room_type'].map({'A': 0, 'B': 1,\n",
        "                        'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'L': 8})\n",
        "df_cat.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkxnkHdK6C3f"
      },
      "source": [
        "➡️ Observe y analice los valores de la variable meal:\n",
        "\n",
        "SC: No meal\n",
        "BB: BED AND BREAKFAST\n",
        "HB: Half board\n",
        "FB: FULL BOARD (PENSIÓN COMPLETA)\n",
        "Undefined: No definido el régimen de comida\n",
        "➡️ Si no estuviera la categoría de Undefined, se pusiera numerizar 1 a 1, pero al existir, no es posible. Se puedieran eliminar esos registros o tratarlos como datos faltantes, si son pocos.\n",
        "\n",
        "➡️ Observe y analice la variable market_segment:\n",
        "\n",
        "Direct\n",
        "Corporate\n",
        "Online Travel Agents\n",
        "Offline Travel Agents/Tours Operators\n",
        "Complementary\n",
        "Groups\n",
        "Undefined\n",
        "Aviontion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta0I-3oY6MA_"
      },
      "source": [
        "➡️ ¿Pueden determinar un orden natural en los datos? No se puede. Numerizar de esta forma sería un error:\n",
        "\n",
        "cat df/market_segment] = cat_df/market segment)map(f Direct: 0, “Corporate: 1, Online TA: 2, Ofine TA/TO: 3, ‘Complementary: 4, ‘Groups’: 5, Undefined: 6, ‘Aviation’: 7))\n",
        "\n",
        "➡️ Para las siguientes variables no se puede realizar el mismo proceso, pues son variables Nominales, no tienen un orden natural, y numerizarlas 1 a 1 sería introducir un error grave en los datos y en las salidas de cualquier algoritmo. Hay que numerizar de 1 a N, creando variable dummies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZF8vCxu6V-k"
      },
      "outputs": [],
      "source": [
        "df_cat = pd.get_dummies(df_cat, columns = [\"distribution_channel\"])\n",
        "df_cat = pd.get_dummies(df_cat, columns = [\"customer_type\"])\n",
        "df_cat = pd.get_dummies(df_cat, columns = [\"deposit_type\"])\n",
        "df_cat.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEk8fKMu6hXb"
      },
      "source": [
        "**Paso 20. Técnicas de muestreo:**\n",
        "Si el objetivo fuera predecir la variable is_canceled se deberia analizar el balance de cada una de las clases, a continuación se muestran en un gráficos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af2CjuMU6kHs"
      },
      "outputs": [],
      "source": [
        "#Variable sі la reserva fue cancelada o no\n",
        "sns.countplot(data=df, x = 'is_canceled')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8c3vxFW60sC"
      },
      "source": [
        "➡️ Es evidente que hay más datos de una que de la otra, pudiera aplicarse una técnicas de submuestreo para balancear las clases:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9sshGYMIxV4"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Contar las clases:\n",
        "count_class_No, count_class_Yes = df[\"is_canceled\"].value_counts()\n",
        "\n",
        "#Dividir los dataframes por las clases:\n",
        "df_class_No = df[df[\"is_canceled\"] == 0]\n",
        "df_class_Yes = df[df[\"is_canceled\"] == 1]\n",
        "\n",
        "#submuestrear la clase mayoritaria No:\n",
        "no_downsampled = resample(df_class_No,\n",
        "                      replace=False, # muestra sin reemplazo\n",
        "                      n_samples = count_class_Yes, # Número de muestras a generar\n",
        "\n",
        "                      random_state = 27) # resultados reproducibles\n",
        "                      #combinar dataframes\n",
        "df_sample = pd.concat([df_class_Yes, no_downsampled])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZimrrdj69JU"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df_sample, x = 'is_canceled')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHsxuhqnnNJf"
      },
      "source": [
        "**Consideraciones finales:**\n",
        "Suponiendo existe un atributo del dataframe df.precio con un formato similar a este $1,560.50 y queremos corregir el dato a tipo float\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjCJFA9onN5x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd1\n",
        "\n",
        "# Ejemplo de datos\n",
        "data = {'precio': ['$1,560.50', '$2,340.75', '$980.25']}\n",
        "df1 = pd1.DataFrame(data)\n",
        "print(\"Antes de la conversión\")\n",
        "print(df1)\n",
        "\n",
        "# Convertir a float\n",
        "df1['precio'] = df1['precio'].str.replace('[\\$,]', '', regex=True).astype(float)\n",
        "print(\"Después de la conversión\")\n",
        "print(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7m6wDPybxlV"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# MODELO DE REGRESIÓN: Predicción del ADR\n",
        "# =====================================\n",
        "\n",
        "# !pip install sklearn\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Selección de variables predictoras y target\n",
        "X = df.drop(columns=['adr', 'reservation_status', 'reservation_status_date'])\n",
        "y = df['adr']\n",
        "# X contiene todas las columnas potencialmente útiles menos aquellas que podrían sesgar el modelo\n",
        "# o contienen el target.\n",
        "\n",
        "# Codificación de variables categóricas\n",
        "X = pd.get_dummies(X, drop_first=True) # Convierte variables categóricas (tipo texto o categorías) en variables numéricas mediante One-Hot Encoding.\n",
        "# drop_first=True: elimina una de las categorías para evitar multicolinealidad (referencia redundante).\n",
        "# Es buena práctica para regresión lineal.\n",
        "\n",
        "# División en train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un objeto imputador\n",
        "imputer = SimpleImputer(strategy='mean') # o 'mediana', 'más_frecuente'\n",
        "# Crea un objeto que puede reemplazar los valores faltantes (NaN) en el dataset.\n",
        "#strategy='mean': reemplazará los valores faltantes por la media de cada columna.\n",
        "\n",
        "# Ajuste el imputador a los datos de entrenamiento y transforme tanto los datos de entrenamiento como los de prueba\n",
        "X_train = imputer.fit_transform(X_train) # fit: calcula la media de cada columna en X_train.transform: reemplaza los valores faltantes en X_train con esa media.\n",
        "X_test = imputer.transform(X_test) #Se reemplazan los NaN en X_test con las medias calculadas en X_train.\n",
        "# Modelo de regresión lineal\n",
        "reg_model = LinearRegression()\n",
        "# En lugar de utilizar X_train.index, utilice el índice original de antes de la imputación\n",
        "reg_model.fit(X_train, y_train)\n",
        "y_pred = reg_model.predict(X_test)\n",
        "\n",
        "# Evaluación\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R²:\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9AK7HctE1xh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# =====================================\n",
        "# Visualización de métricas para el modelo de regresión\n",
        "# =====================================\n",
        "\n",
        "# Realizar predicciones usando el modelo de regresión\n",
        "y_pred_reg = reg_model.predict(X_test) # Asignar a y_pred_reg\n",
        "\n",
        "# Gráfico de dispersión de valores predichos vs. reales\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred_reg, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)  # Línea de referencia\n",
        "plt.xlabel('Valor real')\n",
        "plt.ylabel('Valor predicho')\n",
        "plt.title('Regresión: Valores predichos vs. reales')\n",
        "plt.show()\n",
        "\n",
        "# Histograma de residuos\n",
        "residuals = y_test - y_pred_reg\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(residuals, kde=True) # kde=True: agrega una curva de densidad suavizada (KDE = Kernel Density Estimation),\n",
        "#que ayuda a ver la forma general de la distribución.\n",
        "plt.xlabel('Residuos')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Regresión: Histograma de residuos')\n",
        "plt.show()\n",
        "\n",
        "# Imprimir métricas\n",
        "print(\"Regresión:\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred_reg))\n",
        "print(\"R²:\", r2_score(y_test, y_pred_reg))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwdLZvwL1jQF"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# MODELO DE REGRESIÓN (Redes Neuronales): Predicción del ADR\n",
        "# =====================================\n",
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, explained_variance_score, r2_score\n",
        "\n",
        "# Selección de variables predictoras y target\n",
        "X = df.drop(columns=['adr', 'reservation_status', 'reservation_status_date'])\n",
        "y = df['adr']\n",
        "\n",
        "# Codificación de variables categóricas\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# División en train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Imputación de valores faltantes\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# Escalar los datos (importante para redes neuronales)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define el modelo de red neuronal\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train.shape[1],)),  # Capa entrada\n",
        "    tf.keras.layers.Dense(128, activation='relu'),  # Capa oculta 1\n",
        "    tf.keras.layers.Dense(64, activation='relu'),  # Capa oculta 2\n",
        "    tf.keras.layers.Dense(1)  # Capa salida (sin activación para la regresión)\n",
        "])\n",
        "\n",
        "# Compila el modelo\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "#model.compile(optimizer='RMSprop', loss='mse')\n",
        "#model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "#model.compile(optimizer='adadelta', loss='mean_squared_error')\n",
        "#model.compile(optimizer='adagrad', loss='mean_squared_error')\n",
        "#model.compile(optimizer='adam', loss=tf.keras.losses.Huber())\n",
        "#model.compile(optimizer='adam', loss='log_cosh')\n",
        "#model.compile(optimizer='adam',loss='mean_squared_error', metrics=['mean_absolute_error', 'root_mean_squared_error'])\n",
        "\n",
        "\n",
        "# Entrena el modelo\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32)\n",
        "\n",
        "# Realiza predicciones en el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse**0.5  # o usar mean_squared_error(y_test, y_pred, squared=False)\n",
        "medae = median_absolute_error(y_test, y_pred)\n",
        "explained_variance = explained_variance_score(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"MAE:\", mae)\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"MedAE:\", medae)\n",
        "print(\"Explained Variance:\", explained_variance)\n",
        "print(\"R²:\", r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lrf0CymhCHU5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 1.Diagrama de dispersión de valores previstos frente a valores reales\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)  # alfa para la transparencia\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)  # Línea diagonal\n",
        "plt.xlabel('ADR Real')\n",
        "plt.ylabel('ADR Predicho')\n",
        "plt.title('Regresión de redes neuronales: ADR predicho vs. real')\n",
        "plt.show()\n",
        "\n",
        "# 2. Histograma de residuos (errores de predicción)\n",
        "residuals = y_test - y_pred.flatten()  # Aplanar y_pred si es necesario\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(residuals, kde=True)  # kde para curva de densidad\n",
        "plt.xlabel('Residuos (Actual - Predicho)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Regresión de redes neuronales: Distribución Residual')\n",
        "plt.show()\n",
        "\n",
        "# 3. Imprimir las métricas\n",
        "print(\"Neural Network Regression Metrics:\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R²:\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVL89zi-uaMM"
      },
      "outputs": [],
      "source": [
        "print (df['is_canceled'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af3n_Ac7qttb"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# MODELO DE CLASIFICACIÓN BINARIA (Redes Neuronales): Cancelación de reserva\n",
        "# =====================================\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler  # Importar StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Selección de variables predictoras y target\n",
        "X1 = df.drop(columns=['is_canceled', 'reservation_status', 'reservation_status_date'])\n",
        "# Define la variable objetivo correcta para la predicción de cancelación\n",
        "y1 = df['is_canceled']\n",
        "\n",
        "# Codificación de variables categóricas\n",
        "X1 = pd.get_dummies(X1, drop_first=True)\n",
        "\n",
        "# División en train/test\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un objeto imputador\n",
        "imputer = SimpleImputer(strategy='mean') # o 'mediana', 'más_frecuente'\n",
        "# Crea un objeto que puede reemplazar los valores faltantes (NaN) en el dataset.\n",
        "#strategy='mean': reemplazará los valores faltantes por la media de cada columna.\n",
        "\n",
        "# Ajuste el imputador a los datos de entrenamiento y transforme tanto los datos de entrenamiento como los de prueba\n",
        "X_train1 = imputer.fit_transform(X_train1) # fit: calcula la media de cada columna en X_train.transform: reemplaza los valores faltantes en X_train con esa media.\n",
        "X_test1 = imputer.transform(X_test1) #Se reemplazan los NaN en X_test con las medias calculadas en X_train.\n",
        "\n",
        "# Escalar los datos (importante para redes neuronales)\n",
        "scaler = StandardScaler()\n",
        "X_train1 = scaler.fit_transform(X_train1)\n",
        "X_test1 = scaler.transform(X_test1)\n",
        "\n",
        "# Define el modelo de red neuronal using Input layer\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(X_train1.shape[1],)), # input_shape: define las dimensiones de entrada, que es el número de variables predictoras (columnas en X_train).\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid') #Para clasificación binaria, la última capa suele tener un solo nodo (neurona) con la función de activación sigmoidea\n",
        "])\n",
        "\n",
        "# Compila el modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy', #Pérdida para clasificación binaria.\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Ajustar learning_rate:\n",
        "# model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#model.compile(optimizer='adagrad', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['precision'])\n",
        "# O combinarlas:\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'precision', 'recall', 'f1_score'])\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
        "\n",
        "#Usar una función de pérdida ponderada:\n",
        "#from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Calcula los pesos de las clases\n",
        "#class_weights = compute_class_weight('balanced', classes=np.unique(y_train1), y=y_train1)\n",
        "#class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Compila el modelo con pesos de clase\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'], class_weight=class_weights)\n",
        "\n",
        "\n",
        "# Entrena el modelo\n",
        "model.fit(X_train1, y_train1, epochs=20, batch_size=32) # epochs: es el número de veces que el modelo iterará (pasará por todos los datos de entrenamiento).batch_size: especifica el número de ejemplos de entrenamiento utilizados en cada iteración del ciclo de entrenamiento.\n",
        "#model.fit(X_train1, y_train1, epochs=20, batch_size=64)\n",
        "\n",
        "# Realiza predicciones en el conjunto de prueba\n",
        "y_pred_probs = model.predict(X_test1)\n",
        "y_pred1 = (y_pred_probs > 0.5).astype(int) # Si la probabilidad de cancelación es superior al 0.5, se predice que la reserva se cancelará (1); de lo contrario, se predice que no se cancelará (0).\n",
        "\n",
        "# Evaluar el modelo (con manejo de la división por cero)\n",
        "print(\"Accuracy:\", accuracy_score(y_test1, y_pred1))\n",
        "print(classification_report(y_test1, y_pred1, zero_division=1)) # maneja la división por cero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zo86Io6xnf37"
      },
      "outputs": [],
      "source": [
        "# Visualizar la matriz de confusión\n",
        "# Calcular la matriz de confusión\n",
        "cm = confusion_matrix(y_test1, y_pred1)\n",
        "\n",
        "# Calcular los porcentajes\n",
        "total = np.sum(cm)\n",
        "percentages = (cm / total) * 100\n",
        "\n",
        "# Crear el mapa de calor con porcentajes (solo una llamada a heatmap)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            cbar=False)  # Eliminar barra de color para más espacio\n",
        "\n",
        "# Agregar anotaciones con porcentajes (dentro del mismo heatmap)\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j + 0.5, i + 0.3, f'{percentages[i, j]:.2f}%', # Desplazar hacia arriba\n",
        "                 ha='center', va='center', color='red', fontsize=8)\n",
        "\n",
        "\n",
        "plt.title('Matriz de precisión con porcentajes')\n",
        "plt.ylabel('Clase real')\n",
        "plt.xlabel('Clase predicha')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}